{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e07d3c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "GPUs available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Check gpu \n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPUs available:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d262eb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation done on: /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a large random tensor and perform a matrix multiplication\n",
    "a = tf.random.normal([1000, 1000])\n",
    "b = tf.random.normal([1000, 1000])\n",
    "\n",
    "# This will run on GPU if available\n",
    "c = tf.matmul(a, b)\n",
    "print(\"Computation done on:\", c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e742a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7cefd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6810573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accesing the IP camera\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Replace with your IP camera URL\n",
    "url = \"rtsp://admin:cctv@121@192.168.1.65:554/Streaming/Channels/101\"\n",
    "cap = cv2.VideoCapture(url)\n",
    "\n",
    "# Create a resizable window\n",
    "cv2.namedWindow(\"IP Camera Feed\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"IP Camera Feed\", 640, 360)  # Preview size (smaller window)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    # Show the original full-quality frame in a smaller window\n",
    "    cv2.imshow(\"IP Camera Feed\", frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d69290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Replace with your IP camera URL\n",
    "url = \"rtsp://admin:cctv@121@192.168.1.65:554/Streaming/Channels/101\"\n",
    "cap = cv2.VideoCapture(url)\n",
    "\n",
    "# Create output directory\n",
    "dataset_dir = \"dataset\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "cv2.namedWindow(\"IP Camera Feed\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"IP Camera Feed\", 640, 360)\n",
    "\n",
    "img_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"IP Camera Feed\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('c'):  # Press 'c' to capture\n",
    "        img_path = os.path.join(dataset_dir, f\"face_{img_count}.jpg\")\n",
    "        cv2.imwrite(img_path, frame)\n",
    "        print(f\"Saved {img_path}\")\n",
    "        img_count += 1\n",
    "\n",
    "    elif key == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70bbf109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Replace with your IP camera URL\n",
    "url = \"rtsp://admin:cctv@121@192.168.1.65:554/Streaming/Channels/101\"\n",
    "cap = cv2.VideoCapture(url)\n",
    "\n",
    "# Create output directory\n",
    "dataset_dir = \"dataset\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "cv2.namedWindow(\"IP Camera Feed\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"IP Camera Feed\", 640, 360)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"IP Camera Feed\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('c'):  # Press 'c' to capture\n",
    "        # Ask user for filename\n",
    "        name = input(\"Enter name for this image (without extension): \").strip()\n",
    "        if name == \"\":\n",
    "            print(\"❌ Name cannot be empty. Skipped saving.\")\n",
    "            continue\n",
    "        img_path = os.path.join(dataset_dir, f\"{name}.jpg\")\n",
    "        cv2.imwrite(img_path, frame)\n",
    "        print(f\"✅ Saved {img_path}\")\n",
    "\n",
    "    elif key == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48172726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 31\n",
      "FPS: 16\n",
      "FPS: 15\n",
      "FPS: 16\n",
      "FPS: 15\n",
      "FPS: 16\n",
      "FPS: 15\n",
      "FPS: 15\n",
      "FPS: 15\n",
      "FPS: 16\n",
      "FPS: 16\n",
      "FPS: 16\n",
      "FPS: 16\n",
      "FPS: 15\n",
      "FPS: 16\n",
      "FPS: 15\n",
      "FPS: 15\n"
     ]
    }
   ],
   "source": [
    "# TO check the framerates \n",
    "\n",
    "\n",
    "# ip camera speed test\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "url = \"rtsp://admin:cctv@121@192.168.1.65:554/Streaming/Channels/101\"\n",
    "cap = cv2.VideoCapture(url)\n",
    "\n",
    "cv2.namedWindow(\"IP Camera Feed\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"IP Camera Feed\", 640, 360)\n",
    "\n",
    "fps_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    # Count FPS\n",
    "    fps_count += 1\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if elapsed_time >= 1:  # update every second\n",
    "        print(f\"FPS: {fps_count}\")\n",
    "        fps_count = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "    cv2.imshow(\"IP Camera Feed\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "998aae63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\anaconda3\\envs\\faceenv2\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "import cv2, os, pandas as pd, datetime\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(\"yolov8n-face-lindevs.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1dd8116",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Attendance function\n",
    "# def mark_attendance(name):\n",
    "#     now = datetime.datetime.now()\n",
    "#     date = now.strftime(\"%Y-%m-%d\")\n",
    "#     time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "#     if not os.path.exists(\"attendance.csv\"):\n",
    "#         df = pd.DataFrame(columns=[\"Name\", \"Date\", \"Time\"])\n",
    "#         df.to_csv(\"attendance.csv\", index=False)\n",
    "\n",
    "#     df = pd.read_csv(\"attendance.csv\")\n",
    "\n",
    "#     if not ((df['Name'] == name) & (df['Date'] == date)).any():\n",
    "#         df.loc[len(df)] = [name, date, time]\n",
    "#         df.to_csv(\"attendance.csv\", index=False)\n",
    "#         print(f\"✅ Marked {name} at {time}\")\n",
    "\n",
    "# # Webcam loop\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     results = model(frame)\n",
    "\n",
    "#     for r in results:\n",
    "#         for box in r.boxes.xyxy.cpu().numpy():\n",
    "#             x1, y1, x2, y2 = map(int, box[:4])\n",
    "#             face = frame[y1:y2, x1:x2]\n",
    "\n",
    "#             try:\n",
    "#                 result = DeepFace.find(img_path=face,\n",
    "#                                        db_path=\"dataset/\",\n",
    "#                                        model_name=\"ArcFace\",\n",
    "#                                        enforce_detection=False)\n",
    "\n",
    "#                 if len(result) > 0:\n",
    "#                     name = os.path.basename(os.path.dirname(result.iloc[0]['identity']))\n",
    "#                     mark_attendance(name)\n",
    "#                     cv2.putText(frame, name, (x1, y1-10),\n",
    "#                                 cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(\"Recognition error:\", e)\n",
    "\n",
    "#             cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "\n",
    "#     cv2.imshow(\"YOLO + DeepFace Attendance\", frame)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7408e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mark_attendance(name):\n",
    "    \"\"\"\n",
    "    Records a person's attendance in a CSV file.\n",
    "\n",
    "    This function checks if a person has already been marked for the current day.\n",
    "    If not, it adds their name, the current date, and time to \"attendance.csv\".\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the person to be marked.\n",
    "    \"\"\"\n",
    "    # Get the current date and time\n",
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime(\"%Y-%m-%d\")\n",
    "    time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    # --- CSV File Handling ---\n",
    "\n",
    "    # Check if the attendance file exists. If not, create it with headers.\n",
    "    if not os.path.exists(\"attendance.csv\"):\n",
    "        df = pd.DataFrame(columns=[\"Name\", \"Date\", \"Time\"])\n",
    "        df.to_csv(\"attendance.csv\", index=False)\n",
    "\n",
    "    # Read the existing attendance data from the CSV file\n",
    "    df = pd.read_csv(\"attendance.csv\")\n",
    "\n",
    "    # --- Check for Existing Entry ---\n",
    "\n",
    "    # Check if a row with the same name and today's date already exists\n",
    "    # The '.any()' method returns True if any value in the series is True.\n",
    "    already_marked_today = ((df['Name'] == name) & (df['Date'] == date)).any()\n",
    "\n",
    "    if not already_marked_today:\n",
    "        # If the person has not been marked today, add a new entry\n",
    "        # A new row is created as a list and appended to the DataFrame.\n",
    "        new_entry = [name, date, time]\n",
    "        df.loc[len(df)] = new_entry\n",
    "        \n",
    "        # Save the updated DataFrame back to the CSV file without the index column\n",
    "        df.to_csv(\"attendance.csv\", index=False)\n",
    "        \n",
    "        # Print a confirmation message to the console\n",
    "        print(f\"✅ Marked {name} at {time} on {date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b32577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 123.2ms\n",
      "Speed: 52.3ms preprocess, 123.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 137.8ms\n",
      "Speed: 4.5ms preprocess, 137.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 117.2ms\n",
      "Speed: 3.7ms preprocess, 117.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 97.1ms\n",
      "Speed: 4.6ms preprocess, 97.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 97.6ms\n",
      "Speed: 4.1ms preprocess, 97.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 116.8ms\n",
      "Speed: 4.9ms preprocess, 116.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.7ms\n",
      "Speed: 3.6ms preprocess, 90.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.9ms\n",
      "Speed: 3.9ms preprocess, 89.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.8ms\n",
      "Speed: 4.0ms preprocess, 87.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.3ms\n",
      "Speed: 4.9ms preprocess, 83.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.4ms\n",
      "Speed: 4.0ms preprocess, 83.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.4ms\n",
      "Speed: 3.5ms preprocess, 81.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 75.4ms\n",
      "Speed: 4.2ms preprocess, 75.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.0ms\n",
      "Speed: 4.5ms preprocess, 81.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.1ms\n",
      "Speed: 3.8ms preprocess, 92.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.3ms\n",
      "Speed: 3.6ms preprocess, 81.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.6ms\n",
      "Speed: 3.8ms preprocess, 83.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.2ms\n",
      "Speed: 4.1ms preprocess, 83.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.2ms\n",
      "Speed: 3.7ms preprocess, 84.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 77.0ms\n",
      "Speed: 5.0ms preprocess, 77.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.0ms\n",
      "Speed: 3.9ms preprocess, 80.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 78.6ms\n",
      "Speed: 4.0ms preprocess, 78.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 74.3ms\n",
      "Speed: 3.5ms preprocess, 74.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 75.2ms\n",
      "Speed: 3.8ms preprocess, 75.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.6ms\n",
      "Speed: 3.7ms preprocess, 88.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.4ms\n",
      "Speed: 4.4ms preprocess, 79.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.6ms\n",
      "Speed: 4.4ms preprocess, 83.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.1ms\n",
      "Speed: 3.4ms preprocess, 81.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.6ms\n",
      "Speed: 3.9ms preprocess, 80.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 74.9ms\n",
      "Speed: 4.5ms preprocess, 74.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 77.4ms\n",
      "Speed: 4.1ms preprocess, 77.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 77.3ms\n",
      "Speed: 4.9ms preprocess, 77.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 76.3ms\n",
      "Speed: 4.1ms preprocess, 76.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.6ms\n",
      "Speed: 4.8ms preprocess, 87.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.1ms\n",
      "Speed: 3.7ms preprocess, 79.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 76.2ms\n",
      "Speed: 3.7ms preprocess, 76.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "import cv2, os, pandas as pd, datetime\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(\"yolov8n-face-lindevs.pt\")\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "url = \"rtsp://admin:cctv@121@192.168.1.65:554/Streaming/Channels/101\"\n",
    "# Webcam loop\n",
    "cap = cv2.VideoCapture(url)\n",
    "\n",
    "# Define your thresholds here for easy tuning\n",
    "YOLO_CONF_THRESHOLD = 0.5\n",
    "DEEPFACE_DISTANCE_THRESHOLD = 0.68\n",
    "\n",
    "# Create a resizable window\n",
    "cv2.namedWindow(\"IP Camera Feed\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"IP Camera Feed\", 640, 360)  # Preview size (smaller window)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mark_attendance(name):\n",
    "    \"\"\"\n",
    "    Records a person's attendance in a CSV file.\n",
    "\n",
    "    This function checks if a person has already been marked for the current day.\n",
    "    If not, it adds their name, the current date, and time to \"attendance.csv\".\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the person to be marked.\n",
    "    \"\"\"\n",
    "    # Get the current date and time\n",
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime(\"%Y-%m-%d\")\n",
    "    time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    # --- CSV File Handling ---\n",
    "\n",
    "    # Check if the attendance file exists. If not, create it with headers.\n",
    "    if not os.path.exists(\"attendance.csv\"):\n",
    "        df = pd.DataFrame(columns=[\"Name\", \"Date\", \"Time\"])\n",
    "        df.to_csv(\"attendance.csv\", index=False)\n",
    "\n",
    "    # Read the existing attendance data from the CSV file\n",
    "    df = pd.read_csv(\"attendance.csv\")\n",
    "\n",
    "    # --- Check for Existing Entry ---\n",
    "\n",
    "    # Check if a row with the same name and today's date already exists\n",
    "    # The '.any()' method returns True if any value in the series is True.\n",
    "    already_marked_today = ((df['Name'] == name) & (df['Date'] == date)).any()\n",
    "\n",
    "    if not already_marked_today:\n",
    "        # If the person has not been marked today, add a new entry\n",
    "        # A new row is created as a list and appended to the DataFrame.\n",
    "        new_entry = [name, date, time]\n",
    "        df.loc[len(df)] = new_entry\n",
    "        \n",
    "        # Save the updated DataFrame back to the CSV file without the index column\n",
    "        df.to_csv(\"attendance.csv\", index=False)\n",
    "        \n",
    "        # Print a confirmation message to the console\n",
    "        print(f\"✅ Marked {name} at {time} on {date}\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 1. Apply YOLO confidence threshold\n",
    "    results = model(frame, conf=YOLO_CONF_THRESHOLD)\n",
    "\n",
    "    for r in results:\n",
    "        for box in r.boxes.xyxy.cpu().numpy():\n",
    "            x1, y1, x2, y2 = map(int, box[:4])\n",
    "            \n",
    "            # Draw the bounding box for all detected faces\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            \n",
    "            face = frame[y1:y2, x1:x2]\n",
    "\n",
    "            try:\n",
    "                # 2. Use DeepFace to find the identity\n",
    "                result_df = DeepFace.find(img_path=face,\n",
    "                                          db_path=\"dataset/\",\n",
    "                                          model_name=\"ArcFace\",\n",
    "                                          enforce_detection=False,\n",
    "                                          silent=True) # silent=True suppresses console logs\n",
    "\n",
    "                # Check if a match was found\n",
    "                if len(result_df) > 0 and not result_df[0].empty:\n",
    "                    best_match = result_df[0].iloc[0]\n",
    "                    distance = best_match['distance']\n",
    "\n",
    "                    # 3. Apply DeepFace distance threshold\n",
    "                    if distance < DEEPFACE_DISTANCE_THRESHOLD:\n",
    "                        identity_path = best_match['identity']\n",
    "                        name = os.path.basename(os.path.dirname(identity_path))\n",
    "                        mark_attendance(name)\n",
    "                        cv2.putText(frame, name, (x1, y1 - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                    else:\n",
    "                        cv2.putText(frame, \"Unknown\", (x1, y1 - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "            \n",
    "            except Exception as e:\n",
    "                # Handle potential errors if face crop is invalid etc.\n",
    "                pass\n",
    "\n",
    "    cv2.imshow(\"YOLO + DeepFace Attendance\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "819dd52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 119.1ms\n",
      "Speed: 45.6ms preprocess, 119.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 102.6ms\n",
      "Speed: 2.3ms preprocess, 102.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 102.0ms\n",
      "Speed: 1.9ms preprocess, 102.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.0ms\n",
      "Speed: 1.5ms preprocess, 86.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.7ms\n",
      "Speed: 1.5ms preprocess, 88.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.1ms\n",
      "Speed: 1.8ms preprocess, 83.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.4ms\n",
      "Speed: 1.6ms preprocess, 82.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.6ms\n",
      "Speed: 1.9ms preprocess, 80.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.5ms\n",
      "Speed: 2.5ms preprocess, 90.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.5ms\n",
      "Speed: 1.6ms preprocess, 79.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 74.2ms\n",
      "Speed: 2.4ms preprocess, 74.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.9ms\n",
      "Speed: 1.7ms preprocess, 82.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 77.6ms\n",
      "Speed: 1.6ms preprocess, 77.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.2ms\n",
      "Speed: 1.7ms preprocess, 84.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 77.6ms\n",
      "Speed: 2.3ms preprocess, 77.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 78.1ms\n",
      "Speed: 1.7ms preprocess, 78.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 78.8ms\n",
      "Speed: 1.5ms preprocess, 78.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 77.4ms\n",
      "Speed: 2.1ms preprocess, 77.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 88.9ms\n",
      "Speed: 2.0ms preprocess, 88.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 81.9ms\n",
      "Speed: 1.6ms preprocess, 81.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 79.0ms\n",
      "Speed: 1.5ms preprocess, 79.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 77.9ms\n",
      "Speed: 1.4ms preprocess, 77.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 80.2ms\n",
      "Speed: 1.4ms preprocess, 80.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 79.7ms\n",
      "Speed: 1.5ms preprocess, 79.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 82.9ms\n",
      "Speed: 1.7ms preprocess, 82.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 82.9ms\n",
      "Speed: 1.8ms preprocess, 82.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 87.2ms\n",
      "Speed: 1.6ms preprocess, 87.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 73.1ms\n",
      "Speed: 1.6ms preprocess, 73.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 73.6ms\n",
      "Speed: 1.4ms preprocess, 73.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 75.3ms\n",
      "Speed: 1.5ms preprocess, 75.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 74.4ms\n",
      "Speed: 2.6ms preprocess, 74.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 70.9ms\n",
      "Speed: 1.4ms preprocess, 70.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 74.7ms\n",
      "Speed: 1.5ms preprocess, 74.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 75.2ms\n",
      "Speed: 1.2ms preprocess, 75.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 76.8ms\n",
      "Speed: 1.5ms preprocess, 76.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 78.0ms\n",
      "Speed: 1.8ms preprocess, 78.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 75.7ms\n",
      "Speed: 1.5ms preprocess, 75.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 78.5ms\n",
      "Speed: 2.1ms preprocess, 78.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 74.1ms\n",
      "Speed: 2.2ms preprocess, 74.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 80.3ms\n",
      "Speed: 2.1ms preprocess, 80.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 74.8ms\n",
      "Speed: 1.4ms preprocess, 74.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 81.8ms\n",
      "Speed: 1.6ms preprocess, 81.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 72.7ms\n",
      "Speed: 2.8ms preprocess, 72.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 85.9ms\n",
      "Speed: 1.7ms preprocess, 85.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 73.9ms\n",
      "Speed: 1.4ms preprocess, 73.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 79.6ms\n",
      "Speed: 1.5ms preprocess, 79.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "✅ Attendance Marked: saurabh at 15:22:01 on 2025-09-20\n",
      "\n",
      "0: 384x640 1 face, 74.9ms\n",
      "Speed: 1.4ms preprocess, 74.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 74.4ms\n",
      "Speed: 1.5ms preprocess, 74.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 76.1ms\n",
      "Speed: 1.8ms preprocess, 76.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 76.5ms\n",
      "Speed: 1.5ms preprocess, 76.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 72.5ms\n",
      "Speed: 2.1ms preprocess, 72.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 77.4ms\n",
      "Speed: 1.6ms preprocess, 77.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 75.6ms\n",
      "Speed: 1.6ms preprocess, 75.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 85.2ms\n",
      "Speed: 2.0ms preprocess, 85.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 82.0ms\n",
      "Speed: 2.3ms preprocess, 82.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 77.8ms\n",
      "Speed: 2.1ms preprocess, 77.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 77.4ms\n",
      "Speed: 2.4ms preprocess, 77.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 72.5ms\n",
      "Speed: 1.7ms preprocess, 72.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 71.6ms\n",
      "Speed: 2.3ms preprocess, 71.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Exiting program.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "\n",
    "# --- Configuration ---\n",
    "# URL for your IP camera's RTSP stream.\n",
    "# Replace with your actual camera URL.\n",
    "IP_CAMERA_URL = \"rtsp://admin:cctv@121@192.168.1.65:554/Streaming/Channels/101\"\n",
    "\n",
    "# Path to your downloaded YOLO model\n",
    "YOLO_MODEL_PATH = \"yolov8n-face-lindevs.pt\"\n",
    "\n",
    "# Path to the folder containing known faces\n",
    "DATASET_PATH = \"dataset/\"\n",
    "\n",
    "# --- Thresholds and Settings ---\n",
    "YOLO_CONF_THRESHOLD = 0.6  # Be 60% sure a face is a face\n",
    "# DEEPFACE_DISTANCE_THRESHOLD = 0.68  # For \"ArcFace\" model. Lower is a stricter match.\n",
    "DEEPFACE_DISTANCE_THRESHOLD = 0.5  # For \"ArcFace\" model. Lower is a stricter match.\n",
    "\n",
    "WINDOW_NAME = \"IP Camera Attendance System\"\n",
    "\n",
    "# --- Performance Optimization ---\n",
    "# Instead of processing every frame, we can process every Nth frame.\n",
    "# This drastically reduces CPU/GPU load and makes the stream smoother.\n",
    "PROCESS_EVERY_N_FRAMES = 5 \n",
    "\n",
    "# --- Reconnection Logic ---\n",
    "RECONNECT_DELAY_SECONDS = 5 # How many seconds to wait before trying to reconnect\n",
    "\n",
    "# Load YOLO model\n",
    "try:\n",
    "    model = YOLO(YOLO_MODEL_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLO model: {e}\")\n",
    "    exit()\n",
    "\n",
    "def mark_attendance(name):\n",
    "    \"\"\"\n",
    "    Records a person's attendance in a CSV file. If the person has not been\n",
    "    marked in the last 5 minutes, it adds their name, date, and time.\n",
    "    \"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime(\"%Y-%m-%d\")\n",
    "    time_str = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    csv_file = \"attendance.csv\"\n",
    "    \n",
    "    # Create the CSV if it doesn't exist\n",
    "    if not os.path.exists(csv_file):\n",
    "        df = pd.DataFrame(columns=[\"Name\", \"Date\", \"Time\"])\n",
    "        df.to_csv(csv_file, index=False)\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # --- Time-based Check Logic ---\n",
    "    marked_recently = False\n",
    "    if not df.empty:\n",
    "        # Convert string columns to a single datetime object for comparison\n",
    "        # errors='coerce' will turn any parsing errors into NaT (Not a Time)\n",
    "        df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], errors='coerce')\n",
    "        \n",
    "        # Define the time window: 5 minutes ago from now\n",
    "        five_minutes_ago = now - datetime.timedelta(minutes=5)\n",
    "        \n",
    "        # Check if the person was already marked within the last 5 minutes\n",
    "        marked_recently = not df[(df['Name'] == name) & (df['Timestamp'] > five_minutes_ago)].empty\n",
    "\n",
    "    if not marked_recently:\n",
    "        new_entry = pd.DataFrame([[name, date, time_str]], columns=[\"Name\", \"Date\", \"Time\"])\n",
    "        # The original df does not have 'Timestamp', so we can concat directly after dropping the temporary column\n",
    "        df_updated = pd.concat([df.drop(columns=['Timestamp'], errors='ignore'), new_entry], ignore_index=True)\n",
    "        df_updated.to_csv(csv_file, index=False)\n",
    "        print(f\"✅ Attendance Marked: {name} at {time_str} on {date}\")\n",
    "\n",
    "\n",
    "# Create a resizable window that fits a common screen size\n",
    "cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(WINDOW_NAME, 1280, 720) # A good default size\n",
    "\n",
    "# --- Main Loop ---\n",
    "cap = cv2.VideoCapture(IP_CAMERA_URL)\n",
    "frame_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # --- Automatic Reconnection Logic ---\n",
    "    if not ret:\n",
    "        print(\"❌ Frame not received. Attempting to reconnect...\")\n",
    "        cap.release() # Release the faulty handle\n",
    "        time.sleep(RECONNECT_DELAY_SECONDS)\n",
    "        cap = cv2.VideoCapture(IP_CAMERA_URL)\n",
    "        if not cap.isOpened():\n",
    "            print(\"❌ Failed to reconnect. Check camera and network.\")\n",
    "            time.sleep(RECONNECT_DELAY_SECONDS)\n",
    "        else:\n",
    "            print(\"✅ Reconnected successfully!\")\n",
    "        continue # Skip the rest of the loop for this iteration\n",
    "\n",
    "    frame_counter += 1\n",
    "    \n",
    "    # --- Process Only Every Nth Frame for Performance ---\n",
    "    if frame_counter % PROCESS_EVERY_N_FRAMES == 0:\n",
    "        try:\n",
    "            # Resize frame for faster processing\n",
    "            # A smaller frame is much faster for the models to analyze\n",
    "            process_frame = cv2.resize(frame, (640, 360))\n",
    "\n",
    "            results = model(process_frame, conf=YOLO_CONF_THRESHOLD)\n",
    "\n",
    "            for r in results:\n",
    "                for box in r.boxes.xyxy.cpu().numpy():\n",
    "                    # Scale coordinates back to original frame size for accurate drawing\n",
    "                    x1_s, y1_s, x2_s, y2_s = map(int, box[:4])\n",
    "                    h_orig, w_orig = frame.shape[:2]\n",
    "                    h_proc, w_proc = process_frame.shape[:2]\n",
    "                    \n",
    "                    x1 = int(x1_s * w_orig / w_proc)\n",
    "                    y1 = int(y1_s * h_orig / h_proc)\n",
    "                    x2 = int(x2_s * w_orig / w_proc)\n",
    "                    y2 = int(y2_s * h_orig / h_proc)\n",
    "                    \n",
    "                    # Crop face from the original, high-quality frame\n",
    "                    face = frame[y1:y2, x1:x2]\n",
    "\n",
    "                    if face.size == 0:\n",
    "                        continue # Skip if face crop is empty\n",
    "\n",
    "                    # Use DeepFace to find the identity\n",
    "                    result_df_list = DeepFace.find(img_path=face,\n",
    "                                                   db_path=DATASET_PATH,\n",
    "                                                   model_name=\"ArcFace\",\n",
    "                                                   enforce_detection=False,\n",
    "                                                   silent=True)\n",
    "\n",
    "                    if result_df_list and not result_df_list[0].empty:\n",
    "                        best_match = result_df_list[0].iloc[0]\n",
    "                        distance = best_match['distance']\n",
    "\n",
    "                        if distance < DEEPFACE_DISTANCE_THRESHOLD:\n",
    "                            identity_path = best_match['identity']\n",
    "                            name = os.path.basename(os.path.dirname(identity_path))\n",
    "                            mark_attendance(name)\n",
    "                            # Draw green box and name for recognized person\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                            cv2.putText(frame, name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                        else:\n",
    "                            # Draw red box and \"Unknown\" for unrecognized person\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                            cv2.putText(frame, \"Unknown\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                    else:\n",
    "                        # Draw blue box if face detected but no match found in DB\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during processing: {e}\")\n",
    "\n",
    "    # Display the frame in the resizable window\n",
    "    cv2.imshow(WINDOW_NAME, frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Exiting program.\")\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e273767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "878174e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 face, 115.7ms\n",
      "Speed: 41.9ms preprocess, 115.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 91.3ms\n",
      "Speed: 3.2ms preprocess, 91.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 85.4ms\n",
      "Speed: 1.5ms preprocess, 85.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 84.0ms\n",
      "Speed: 1.2ms preprocess, 84.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 85.4ms\n",
      "Speed: 1.6ms preprocess, 85.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 78.9ms\n",
      "Speed: 2.9ms preprocess, 78.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 83.8ms\n",
      "Speed: 2.6ms preprocess, 83.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 82.6ms\n",
      "Speed: 1.9ms preprocess, 82.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 89.6ms\n",
      "Speed: 2.1ms preprocess, 89.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 82.5ms\n",
      "Speed: 3.1ms preprocess, 82.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 81.7ms\n",
      "Speed: 1.6ms preprocess, 81.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 80.1ms\n",
      "Speed: 1.6ms preprocess, 80.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 75.5ms\n",
      "Speed: 2.5ms preprocess, 75.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 77.2ms\n",
      "Speed: 1.5ms preprocess, 77.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 79.7ms\n",
      "Speed: 1.5ms preprocess, 79.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 83.2ms\n",
      "Speed: 1.7ms preprocess, 83.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 93.0ms\n",
      "Speed: 2.2ms preprocess, 93.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 79.3ms\n",
      "Speed: 1.4ms preprocess, 79.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 80.5ms\n",
      "Speed: 2.2ms preprocess, 80.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "✅ Attendance Marked: saurabh at 15:34:54 (YOLO: 0.79, DeepFace: 0.45)\n",
      "\n",
      "0: 384x640 (no detections), 81.2ms\n",
      "Speed: 1.4ms preprocess, 81.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 78.4ms\n",
      "Speed: 2.1ms preprocess, 78.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 79.3ms\n",
      "Speed: 2.8ms preprocess, 79.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 78.8ms\n",
      "Speed: 1.9ms preprocess, 78.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 84.1ms\n",
      "Speed: 2.5ms preprocess, 84.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 76.5ms\n",
      "Speed: 1.5ms preprocess, 76.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 80.4ms\n",
      "Speed: 2.0ms preprocess, 80.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 81.8ms\n",
      "Speed: 1.7ms preprocess, 81.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 81.7ms\n",
      "Speed: 1.4ms preprocess, 81.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 77.5ms\n",
      "Speed: 1.6ms preprocess, 77.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 101.4ms\n",
      "Speed: 1.6ms preprocess, 101.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 80.7ms\n",
      "Speed: 1.6ms preprocess, 80.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 79.9ms\n",
      "Speed: 1.2ms preprocess, 79.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 77.9ms\n",
      "Speed: 1.7ms preprocess, 77.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 82.1ms\n",
      "Speed: 1.5ms preprocess, 82.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 80.9ms\n",
      "Speed: 2.7ms preprocess, 80.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 81.0ms\n",
      "Speed: 1.4ms preprocess, 81.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 77.7ms\n",
      "Speed: 1.8ms preprocess, 77.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 82.7ms\n",
      "Speed: 1.7ms preprocess, 82.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 78.0ms\n",
      "Speed: 1.7ms preprocess, 78.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Exiting program.\n"
     ]
    }
   ],
   "source": [
    "## with confidece score and distance\n",
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "\n",
    "# --- Configuration ---\n",
    "# URL for your IP camera's RTSP stream.\n",
    "# Replace with your actual camera URL.\n",
    "IP_CAMERA_URL = \"rtsp://admin:cctv@121@192.168.1.65:554/Streaming/Channels/101\"\n",
    "\n",
    "# Path to your downloaded YOLO model\n",
    "YOLO_MODEL_PATH = \"yolov8n-face-lindevs.pt\"\n",
    "\n",
    "# Path to the folder containing known faces\n",
    "DATASET_PATH = \"dataset/\"\n",
    "\n",
    "# --- Thresholds and Settings ---\n",
    "YOLO_CONF_THRESHOLD = 0.6  # Be 60% sure a face is a face\n",
    "DEEPFACE_DISTANCE_THRESHOLD = 0.5  # For \"ArcFace\" model. Lower is a stricter match.\n",
    "WINDOW_NAME = \"IP Camera Attendance System\"\n",
    "\n",
    "# --- Performance Optimization ---\n",
    "PROCESS_EVERY_N_FRAMES = 5 \n",
    "\n",
    "# --- Reconnection Logic ---\n",
    "RECONNECT_DELAY_SECONDS = 5 # How many seconds to wait before trying to reconnect\n",
    "\n",
    "# Load YOLO model\n",
    "try:\n",
    "    model = YOLO(YOLO_MODEL_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLO model: {e}\")\n",
    "    exit()\n",
    "\n",
    "def mark_attendance(name, yolo_confidence, deepface_distance):\n",
    "    \"\"\"\n",
    "    Records a person's attendance in a CSV file, now including YOLO confidence\n",
    "    and DeepFace distance scores.\n",
    "    \"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime(\"%Y-%m-%d\")\n",
    "    time_str = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    csv_file = \"attendance.csv\"\n",
    "    # Define the new columns for the CSV file\n",
    "    csv_columns = [\"Name\", \"Date\", \"Time\", \"YOLO_Confidence\", \"DeepFace_Distance\"]\n",
    "    \n",
    "    # Create the CSV with the new headers if it doesn't exist\n",
    "    if not os.path.exists(csv_file):\n",
    "        df = pd.DataFrame(columns=csv_columns)\n",
    "        df.to_csv(csv_file, index=False)\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # --- Time-based Check Logic ---\n",
    "    marked_recently = False\n",
    "    if not df.empty:\n",
    "        # We need to handle cases where old CSVs might not have the Timestamp data\n",
    "        if 'Date' in df.columns and 'Time' in df.columns:\n",
    "            df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], errors='coerce')\n",
    "            five_minutes_ago = now - datetime.timedelta(minutes=5)\n",
    "            marked_recently = not df[(df['Name'] == name) & (df['Timestamp'] > five_minutes_ago)].empty\n",
    "\n",
    "    if not marked_recently:\n",
    "        # Format scores to 2 decimal places for cleaner output\n",
    "        yolo_conf_str = f\"{yolo_confidence:.2f}\"\n",
    "        deepface_dist_str = f\"{deepface_distance:.2f}\"\n",
    "        \n",
    "        new_entry = pd.DataFrame(\n",
    "            [[name, date, time_str, yolo_conf_str, deepface_dist_str]],\n",
    "            columns=csv_columns\n",
    "        )\n",
    "\n",
    "        # Drop the temporary Timestamp column if it exists before concatenating\n",
    "        df_updated = pd.concat([df.drop(columns=['Timestamp'], errors='ignore'), new_entry], ignore_index=True)\n",
    "        df_updated.to_csv(csv_file, index=False)\n",
    "        print(f\"✅ Attendance Marked: {name} at {time_str} (YOLO: {yolo_conf_str}, DeepFace: {deepface_dist_str})\")\n",
    "\n",
    "# Create a resizable window\n",
    "cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(WINDOW_NAME, 1280, 720)\n",
    "\n",
    "# --- Main Loop ---\n",
    "cap = cv2.VideoCapture(IP_CAMERA_URL)\n",
    "frame_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # --- Automatic Reconnection Logic ---\n",
    "    if not ret:\n",
    "        print(\"❌ Frame not received. Attempting to reconnect...\")\n",
    "        cap.release()\n",
    "        time.sleep(RECONNECT_DELAY_SECONDS)\n",
    "        cap = cv2.VideoCapture(IP_CAMERA_URL)\n",
    "        if not cap.isOpened():\n",
    "            print(\"❌ Failed to reconnect.\")\n",
    "            time.sleep(RECONNECT_DELAY_SECONDS)\n",
    "        else:\n",
    "            print(\"✅ Reconnected successfully!\")\n",
    "        continue\n",
    "\n",
    "    frame_counter += 1\n",
    "    \n",
    "    if frame_counter % PROCESS_EVERY_N_FRAMES == 0:\n",
    "        try:\n",
    "            process_frame = cv2.resize(frame, (640, 360))\n",
    "            results = model(process_frame, conf=YOLO_CONF_THRESHOLD)\n",
    "\n",
    "            for r in results:\n",
    "                # Iterate over each box object to access all its properties\n",
    "                for box in r.boxes:\n",
    "                    # Get the confidence score for this specific detection\n",
    "                    yolo_confidence = box.conf.item() # .item() extracts the float value\n",
    "                    \n",
    "                    # Get coordinates\n",
    "                    x1_s, y1_s, x2_s, y2_s = map(int, box.xyxy[0].cpu().numpy())\n",
    "                    \n",
    "                    # Scale coordinates back to original frame size\n",
    "                    h_orig, w_orig = frame.shape[:2]\n",
    "                    h_proc, w_proc = process_frame.shape[:2]\n",
    "                    x1 = int(x1_s * w_orig / w_proc)\n",
    "                    y1 = int(y1_s * h_orig / h_proc)\n",
    "                    x2 = int(x2_s * w_orig / w_proc)\n",
    "                    y2 = int(y2_s * h_orig / h_proc)\n",
    "                    \n",
    "                    face = frame[y1:y2, x1:x2]\n",
    "                    if face.size == 0:\n",
    "                        continue\n",
    "\n",
    "                    result_df_list = DeepFace.find(img_path=face,\n",
    "                                                   db_path=DATASET_PATH,\n",
    "                                                   model_name=\"ArcFace\",\n",
    "                                                   enforce_detection=False,\n",
    "                                                   silent=True)\n",
    "\n",
    "                    if result_df_list and not result_df_list[0].empty:\n",
    "                        best_match = result_df_list[0].iloc[0]\n",
    "                        distance = best_match['distance']\n",
    "\n",
    "                        if distance < DEEPFACE_DISTANCE_THRESHOLD:\n",
    "                            identity_path = best_match['identity']\n",
    "                            name = os.path.basename(os.path.dirname(identity_path))\n",
    "                            \n",
    "                            # *** PASS THE SCORES TO THE FUNCTION ***\n",
    "                            mark_attendance(name, yolo_confidence, distance)\n",
    "                            \n",
    "                            # Draw green box and name for recognized person\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                            cv2.putText(frame, name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                        else:\n",
    "                            # Draw red box and \"Unknown\"\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                            cv2.putText(frame, \"Unknown\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                    else:\n",
    "                        # Draw blue box if face detected but no match found in DB\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during processing: {e}\")\n",
    "\n",
    "    cv2.imshow(WINDOW_NAME, frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Exiting program.\")\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89552044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\anaconda3\\envs\\faceenv2\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "0: 384x640 (no detections), 184.9ms\n",
      "Speed: 6.2ms preprocess, 184.9ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.0ms\n",
      "Speed: 2.3ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 135.3ms\n",
      "Speed: 2.4ms preprocess, 135.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 142.0ms\n",
      "Speed: 3.4ms preprocess, 142.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 135.3ms\n",
      "Speed: 2.4ms preprocess, 135.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 137.9ms\n",
      "Speed: 2.7ms preprocess, 137.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 149.7ms\n",
      "Speed: 3.0ms preprocess, 149.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 144.4ms\n",
      "Speed: 2.6ms preprocess, 144.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 145.8ms\n",
      "Speed: 2.9ms preprocess, 145.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 130.7ms\n",
      "Speed: 3.1ms preprocess, 130.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 132.6ms\n",
      "Speed: 5.4ms preprocess, 132.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 135.9ms\n",
      "Speed: 2.6ms preprocess, 135.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 135.8ms\n",
      "Speed: 2.6ms preprocess, 135.8ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "✅ Attendance Marked: Meena at 20:56:02 (YOLO: 0.76, DeepFace: 0.01)\n",
      "\n",
      "0: 384x640 1 face, 145.7ms\n",
      "Speed: 2.8ms preprocess, 145.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 193.2ms\n",
      "Speed: 4.0ms preprocess, 193.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 153.9ms\n",
      "Speed: 3.3ms preprocess, 153.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 153.0ms\n",
      "Speed: 3.2ms preprocess, 153.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 143.8ms\n",
      "Speed: 3.9ms preprocess, 143.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 156.3ms\n",
      "Speed: 2.6ms preprocess, 156.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 148.4ms\n",
      "Speed: 3.4ms preprocess, 148.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 145.3ms\n",
      "Speed: 2.7ms preprocess, 145.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "✅ Attendance Marked: Onkar at 20:56:08 (YOLO: 0.80, DeepFace: 0.08)\n",
      "\n",
      "0: 384x640 1 face, 143.9ms\n",
      "Speed: 2.2ms preprocess, 143.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 148.8ms\n",
      "Speed: 2.6ms preprocess, 148.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 131.8ms\n",
      "Speed: 2.6ms preprocess, 131.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 129.3ms\n",
      "Speed: 2.7ms preprocess, 129.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 138.1ms\n",
      "Speed: 2.4ms preprocess, 138.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 160.9ms\n",
      "Speed: 3.6ms preprocess, 160.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 141.0ms\n",
      "Speed: 2.5ms preprocess, 141.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 122.9ms\n",
      "Speed: 4.4ms preprocess, 122.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 105.9ms\n",
      "Speed: 3.2ms preprocess, 105.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 157.2ms\n",
      "Speed: 68.5ms preprocess, 157.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 171.4ms\n",
      "Speed: 2.7ms preprocess, 171.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 111.0ms\n",
      "Speed: 2.9ms preprocess, 111.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 95.0ms\n",
      "Speed: 1.8ms preprocess, 95.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 95.4ms\n",
      "Speed: 1.9ms preprocess, 95.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 100.1ms\n",
      "Speed: 2.1ms preprocess, 100.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 117.1ms\n",
      "Speed: 2.2ms preprocess, 117.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 126.2ms\n",
      "Speed: 2.0ms preprocess, 126.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 121.1ms\n",
      "Speed: 2.8ms preprocess, 121.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 131.4ms\n",
      "Speed: 2.4ms preprocess, 131.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 134.9ms\n",
      "Speed: 2.3ms preprocess, 134.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 171.6ms\n",
      "Speed: 3.1ms preprocess, 171.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 138.0ms\n",
      "Speed: 2.6ms preprocess, 138.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 138.9ms\n",
      "Speed: 2.2ms preprocess, 138.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 115.8ms\n",
      "Speed: 2.0ms preprocess, 115.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 132.5ms\n",
      "Speed: 2.4ms preprocess, 132.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 163.3ms\n",
      "Speed: 1.8ms preprocess, 163.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 133.3ms\n",
      "Speed: 2.9ms preprocess, 133.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 138.9ms\n",
      "Speed: 3.5ms preprocess, 138.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 112.1ms\n",
      "Speed: 1.9ms preprocess, 112.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 131.9ms\n",
      "Speed: 2.3ms preprocess, 131.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.8ms\n",
      "Speed: 2.1ms preprocess, 126.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 170.3ms\n",
      "Speed: 2.9ms preprocess, 170.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 180.8ms\n",
      "Speed: 3.4ms preprocess, 180.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 168.3ms\n",
      "Speed: 3.8ms preprocess, 168.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 165.1ms\n",
      "Speed: 3.0ms preprocess, 165.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 172.6ms\n",
      "Speed: 3.0ms preprocess, 172.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 166.3ms\n",
      "Speed: 3.7ms preprocess, 166.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 172.3ms\n",
      "Speed: 3.8ms preprocess, 172.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 163.7ms\n",
      "Speed: 3.4ms preprocess, 163.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 147.2ms\n",
      "Speed: 3.4ms preprocess, 147.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 145.6ms\n",
      "Speed: 2.6ms preprocess, 145.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 160.0ms\n",
      "Speed: 2.9ms preprocess, 160.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 167.6ms\n",
      "Speed: 3.5ms preprocess, 167.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 167.4ms\n",
      "Speed: 3.2ms preprocess, 167.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 171.6ms\n",
      "Speed: 3.1ms preprocess, 171.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 166.3ms\n",
      "Speed: 3.5ms preprocess, 166.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 176.6ms\n",
      "Speed: 3.1ms preprocess, 176.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 197.2ms\n",
      "Speed: 3.8ms preprocess, 197.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 176.9ms\n",
      "Speed: 4.1ms preprocess, 176.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 179.8ms\n",
      "Speed: 4.1ms preprocess, 179.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 175.2ms\n",
      "Speed: 3.1ms preprocess, 175.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 191.8ms\n",
      "Speed: 3.6ms preprocess, 191.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 172.7ms\n",
      "Speed: 3.1ms preprocess, 172.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 136.7ms\n",
      "Speed: 2.6ms preprocess, 136.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 142.1ms\n",
      "Speed: 2.1ms preprocess, 142.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "✅ Attendance Marked: saurabh at 20:56:39 (YOLO: 0.86, DeepFace: 0.39)\n",
      "\n",
      "0: 384x640 1 face, 159.5ms\n",
      "Speed: 2.7ms preprocess, 159.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 159.4ms\n",
      "Speed: 3.0ms preprocess, 159.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 152.7ms\n",
      "Speed: 3.0ms preprocess, 152.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 148.9ms\n",
      "Speed: 2.5ms preprocess, 148.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 150.9ms\n",
      "Speed: 3.7ms preprocess, 150.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 179.9ms\n",
      "Speed: 4.4ms preprocess, 179.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 141.8ms\n",
      "Speed: 2.5ms preprocess, 141.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 113.8ms\n",
      "Speed: 2.4ms preprocess, 113.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 140.4ms\n",
      "Speed: 48.0ms preprocess, 140.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 163.3ms\n",
      "Speed: 2.6ms preprocess, 163.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 145.9ms\n",
      "Speed: 3.0ms preprocess, 145.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 114.3ms\n",
      "Speed: 2.2ms preprocess, 114.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 107.7ms\n",
      "Speed: 2.1ms preprocess, 107.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 109.2ms\n",
      "Speed: 1.6ms preprocess, 109.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 130.2ms\n",
      "Speed: 2.5ms preprocess, 130.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 119.8ms\n",
      "Speed: 2.3ms preprocess, 119.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 100.5ms\n",
      "Speed: 1.9ms preprocess, 100.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 109.5ms\n",
      "Speed: 2.1ms preprocess, 109.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 116.1ms\n",
      "Speed: 2.2ms preprocess, 116.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 99.8ms\n",
      "Speed: 2.1ms preprocess, 99.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 faces, 108.3ms\n",
      "Speed: 1.9ms preprocess, 108.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 134.0ms\n",
      "Speed: 2.6ms preprocess, 134.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 155.7ms\n",
      "Speed: 3.4ms preprocess, 155.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 152.0ms\n",
      "Speed: 2.7ms preprocess, 152.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 148.4ms\n",
      "Speed: 2.8ms preprocess, 148.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 152.5ms\n",
      "Speed: 2.8ms preprocess, 152.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 158.4ms\n",
      "Speed: 2.9ms preprocess, 158.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 140.1ms\n",
      "Speed: 2.8ms preprocess, 140.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 127.3ms\n",
      "Speed: 2.6ms preprocess, 127.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 133.3ms\n",
      "Speed: 2.9ms preprocess, 133.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 129.0ms\n",
      "Speed: 2.4ms preprocess, 129.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 183.4ms\n",
      "Speed: 2.1ms preprocess, 183.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 164.8ms\n",
      "Speed: 3.4ms preprocess, 164.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 160.3ms\n",
      "Speed: 2.9ms preprocess, 160.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 151.8ms\n",
      "Speed: 2.8ms preprocess, 151.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 151.7ms\n",
      "Speed: 3.1ms preprocess, 151.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 152.0ms\n",
      "Speed: 3.1ms preprocess, 152.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 143.9ms\n",
      "Speed: 3.0ms preprocess, 143.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 146.7ms\n",
      "Speed: 2.8ms preprocess, 146.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 164.2ms\n",
      "Speed: 3.0ms preprocess, 164.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 160.8ms\n",
      "Speed: 2.9ms preprocess, 160.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 155.1ms\n",
      "Speed: 2.8ms preprocess, 155.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 173.6ms\n",
      "Speed: 2.7ms preprocess, 173.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 191.3ms\n",
      "Speed: 4.3ms preprocess, 191.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 175.8ms\n",
      "Speed: 3.8ms preprocess, 175.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 167.0ms\n",
      "Speed: 2.8ms preprocess, 167.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 167.0ms\n",
      "Speed: 3.2ms preprocess, 167.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 165.4ms\n",
      "Speed: 3.5ms preprocess, 165.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 165.3ms\n",
      "Speed: 3.1ms preprocess, 165.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 158.7ms\n",
      "Speed: 2.8ms preprocess, 158.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 146.3ms\n",
      "Speed: 3.3ms preprocess, 146.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 148.8ms\n",
      "Speed: 2.5ms preprocess, 148.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 142.9ms\n",
      "Speed: 2.8ms preprocess, 142.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 156.9ms\n",
      "Speed: 3.0ms preprocess, 156.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 148.2ms\n",
      "Speed: 2.9ms preprocess, 148.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 156.8ms\n",
      "Speed: 2.4ms preprocess, 156.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 166.1ms\n",
      "Speed: 3.2ms preprocess, 166.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 159.1ms\n",
      "Speed: 2.7ms preprocess, 159.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 164.3ms\n",
      "Speed: 3.0ms preprocess, 164.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 155.0ms\n",
      "Speed: 3.6ms preprocess, 155.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 168.8ms\n",
      "Speed: 2.7ms preprocess, 168.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 153.4ms\n",
      "Speed: 3.1ms preprocess, 153.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 155.5ms\n",
      "Speed: 3.2ms preprocess, 155.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 144.6ms\n",
      "Speed: 2.8ms preprocess, 144.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 140.3ms\n",
      "Speed: 2.9ms preprocess, 140.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 135.4ms\n",
      "Speed: 3.0ms preprocess, 135.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 150.5ms\n",
      "Speed: 2.6ms preprocess, 150.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 147.0ms\n",
      "Speed: 2.9ms preprocess, 147.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 142.6ms\n",
      "Speed: 3.4ms preprocess, 142.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 146.9ms\n",
      "Speed: 2.6ms preprocess, 146.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.6ms\n",
      "Speed: 2.8ms preprocess, 124.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 164.6ms\n",
      "Speed: 2.7ms preprocess, 164.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 183.7ms\n",
      "Speed: 3.4ms preprocess, 183.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 165.7ms\n",
      "Speed: 3.2ms preprocess, 165.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 160.9ms\n",
      "Speed: 70.5ms preprocess, 160.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 167.7ms\n",
      "Speed: 2.8ms preprocess, 167.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 162.9ms\n",
      "Speed: 2.8ms preprocess, 162.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 180.4ms\n",
      "Speed: 3.1ms preprocess, 180.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 174.5ms\n",
      "Speed: 3.2ms preprocess, 174.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 150.0ms\n",
      "Speed: 2.4ms preprocess, 150.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 129.9ms\n",
      "Speed: 2.8ms preprocess, 129.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 139.0ms\n",
      "Speed: 2.0ms preprocess, 139.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 142.4ms\n",
      "Speed: 2.3ms preprocess, 142.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 144.6ms\n",
      "Speed: 2.6ms preprocess, 144.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.5ms\n",
      "Speed: 2.5ms preprocess, 123.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 119.3ms\n",
      "Speed: 2.1ms preprocess, 119.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.8ms\n",
      "Speed: 2.8ms preprocess, 124.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 159.1ms\n",
      "Speed: 4.1ms preprocess, 159.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 141.2ms\n",
      "Speed: 3.2ms preprocess, 141.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 152.2ms\n",
      "Speed: 3.0ms preprocess, 152.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 144.1ms\n",
      "Speed: 3.0ms preprocess, 144.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 151.6ms\n",
      "Speed: 2.9ms preprocess, 151.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 129.4ms\n",
      "Speed: 2.5ms preprocess, 129.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.8ms\n",
      "Speed: 2.3ms preprocess, 122.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 124.4ms\n",
      "Speed: 2.7ms preprocess, 124.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 108.9ms\n",
      "Speed: 2.2ms preprocess, 108.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 109.7ms\n",
      "Speed: 2.9ms preprocess, 109.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 105.4ms\n",
      "Speed: 2.1ms preprocess, 105.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 112.2ms\n",
      "Speed: 2.4ms preprocess, 112.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 117.8ms\n",
      "Speed: 2.3ms preprocess, 117.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 119.9ms\n",
      "Speed: 2.5ms preprocess, 119.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 130.7ms\n",
      "Speed: 2.3ms preprocess, 130.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 116.3ms\n",
      "Speed: 2.4ms preprocess, 116.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.8ms\n",
      "Speed: 2.3ms preprocess, 122.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 155.5ms\n",
      "Speed: 4.1ms preprocess, 155.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 143.6ms\n",
      "Speed: 3.8ms preprocess, 143.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 135.4ms\n",
      "Speed: 2.4ms preprocess, 135.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 127.5ms\n",
      "Speed: 2.7ms preprocess, 127.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 133.8ms\n",
      "Speed: 3.3ms preprocess, 133.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.6ms\n",
      "Speed: 2.7ms preprocess, 126.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 137.6ms\n",
      "Speed: 2.7ms preprocess, 137.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 138.1ms\n",
      "Speed: 2.3ms preprocess, 138.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.3ms\n",
      "Speed: 2.9ms preprocess, 122.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 115.5ms\n",
      "Speed: 2.1ms preprocess, 115.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.3ms\n",
      "Speed: 2.0ms preprocess, 100.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 120.2ms\n",
      "Speed: 1.9ms preprocess, 120.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 118.4ms\n",
      "Speed: 2.2ms preprocess, 118.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 120.3ms\n",
      "Speed: 2.5ms preprocess, 120.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.1ms\n",
      "Speed: 2.4ms preprocess, 122.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 130.4ms\n",
      "Speed: 2.8ms preprocess, 130.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.9ms\n",
      "Speed: 2.7ms preprocess, 122.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 170.3ms\n",
      "Speed: 3.3ms preprocess, 170.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 154.2ms\n",
      "Speed: 2.8ms preprocess, 154.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 127.5ms\n",
      "Speed: 2.7ms preprocess, 127.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 130.5ms\n",
      "Speed: 2.8ms preprocess, 130.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 164.9ms\n",
      "Speed: 2.9ms preprocess, 164.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 133.8ms\n",
      "Speed: 2.9ms preprocess, 133.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 130.1ms\n",
      "Speed: 3.2ms preprocess, 130.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 134.7ms\n",
      "Speed: 2.9ms preprocess, 134.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 117.1ms\n",
      "Speed: 2.6ms preprocess, 117.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 106.4ms\n",
      "Speed: 2.0ms preprocess, 106.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 104.9ms\n",
      "Speed: 2.3ms preprocess, 104.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 120.0ms\n",
      "Speed: 2.0ms preprocess, 120.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 138.9ms\n",
      "Speed: 2.7ms preprocess, 138.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 143.3ms\n",
      "Speed: 3.0ms preprocess, 143.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 141.4ms\n",
      "Speed: 3.4ms preprocess, 141.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 149.5ms\n",
      "Speed: 2.7ms preprocess, 149.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 145.1ms\n",
      "Speed: 2.9ms preprocess, 145.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 212.2ms\n",
      "Speed: 3.9ms preprocess, 212.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 190.2ms\n",
      "Speed: 3.7ms preprocess, 190.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 174.0ms\n",
      "Speed: 3.4ms preprocess, 174.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 166.8ms\n",
      "Speed: 3.2ms preprocess, 166.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 165.1ms\n",
      "Speed: 2.9ms preprocess, 165.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 165.4ms\n",
      "Speed: 3.1ms preprocess, 165.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 168.2ms\n",
      "Speed: 3.2ms preprocess, 168.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 159.6ms\n",
      "Speed: 3.1ms preprocess, 159.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 141.5ms\n",
      "Speed: 2.5ms preprocess, 141.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 147.2ms\n",
      "Speed: 2.9ms preprocess, 147.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 161.0ms\n",
      "Speed: 2.9ms preprocess, 161.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 165.5ms\n",
      "Speed: 4.7ms preprocess, 165.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 161.1ms\n",
      "Speed: 3.1ms preprocess, 161.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 169.8ms\n",
      "Speed: 2.9ms preprocess, 169.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 177.4ms\n",
      "Speed: 2.9ms preprocess, 177.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 238.0ms\n",
      "Speed: 4.0ms preprocess, 238.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 193.4ms\n",
      "Speed: 4.0ms preprocess, 193.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 182.9ms\n",
      "Speed: 3.4ms preprocess, 182.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 186.3ms\n",
      "Speed: 4.5ms preprocess, 186.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 185.2ms\n",
      "Speed: 3.4ms preprocess, 185.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 178.1ms\n",
      "Speed: 3.0ms preprocess, 178.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 171.9ms\n",
      "Speed: 4.4ms preprocess, 171.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 163.2ms\n",
      "Speed: 3.5ms preprocess, 163.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 164.2ms\n",
      "Speed: 3.2ms preprocess, 164.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 227.4ms\n",
      "Speed: 3.9ms preprocess, 227.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 200.1ms\n",
      "Speed: 3.7ms preprocess, 200.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 195.2ms\n",
      "Speed: 3.5ms preprocess, 195.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 183.1ms\n",
      "Speed: 3.1ms preprocess, 183.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 186.9ms\n",
      "Speed: 3.9ms preprocess, 186.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 179.0ms\n",
      "Speed: 3.1ms preprocess, 179.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 177.2ms\n",
      "Speed: 3.1ms preprocess, 177.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 155.7ms\n",
      "Speed: 2.8ms preprocess, 155.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 152.2ms\n",
      "Speed: 2.9ms preprocess, 152.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 165.0ms\n",
      "Speed: 2.8ms preprocess, 165.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 181.4ms\n",
      "Speed: 2.9ms preprocess, 181.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 182.3ms\n",
      "Speed: 3.5ms preprocess, 182.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 189.2ms\n",
      "Speed: 3.7ms preprocess, 189.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 200.7ms\n",
      "Speed: 3.7ms preprocess, 200.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 178.8ms\n",
      "Speed: 4.0ms preprocess, 178.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 220.0ms\n",
      "Speed: 4.2ms preprocess, 220.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 210.4ms\n",
      "Speed: 3.5ms preprocess, 210.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 197.2ms\n",
      "Speed: 4.0ms preprocess, 197.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 181.0ms\n",
      "Speed: 3.3ms preprocess, 181.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 162.7ms\n",
      "Speed: 2.9ms preprocess, 162.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 174.0ms\n",
      "Speed: 3.6ms preprocess, 174.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 151.0ms\n",
      "Speed: 3.6ms preprocess, 151.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 137.8ms\n",
      "Speed: 2.5ms preprocess, 137.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 153.2ms\n",
      "Speed: 66.8ms preprocess, 153.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 152.2ms\n",
      "Speed: 2.9ms preprocess, 152.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 182.4ms\n",
      "Speed: 3.0ms preprocess, 182.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 174.6ms\n",
      "Speed: 4.7ms preprocess, 174.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 180.6ms\n",
      "Speed: 3.5ms preprocess, 180.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 176.7ms\n",
      "Speed: 3.3ms preprocess, 176.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 147.3ms\n",
      "Speed: 2.7ms preprocess, 147.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 174.5ms\n",
      "Speed: 2.6ms preprocess, 174.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 183.0ms\n",
      "Speed: 3.1ms preprocess, 183.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 184.9ms\n",
      "Speed: 3.0ms preprocess, 184.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 140.1ms\n",
      "Speed: 3.1ms preprocess, 140.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 139.8ms\n",
      "Speed: 2.5ms preprocess, 139.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 148.1ms\n",
      "Speed: 3.3ms preprocess, 148.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 138.7ms\n",
      "Speed: 2.7ms preprocess, 138.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 168.7ms\n",
      "Speed: 3.1ms preprocess, 168.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 175.5ms\n",
      "Speed: 2.9ms preprocess, 175.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 173.0ms\n",
      "Speed: 3.1ms preprocess, 173.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 180.1ms\n",
      "Speed: 3.4ms preprocess, 180.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 182.5ms\n",
      "Speed: 4.1ms preprocess, 182.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 176.1ms\n",
      "Speed: 4.2ms preprocess, 176.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 176.1ms\n",
      "Speed: 3.4ms preprocess, 176.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 179.9ms\n",
      "Speed: 3.4ms preprocess, 179.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 175.2ms\n",
      "Speed: 3.6ms preprocess, 175.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 173.1ms\n",
      "Speed: 3.2ms preprocess, 173.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 181.4ms\n",
      "Speed: 3.4ms preprocess, 181.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 182.1ms\n",
      "Speed: 4.2ms preprocess, 182.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 173.5ms\n",
      "Speed: 3.2ms preprocess, 173.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 153.8ms\n",
      "Speed: 4.2ms preprocess, 153.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 163.7ms\n",
      "Speed: 3.3ms preprocess, 163.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 173.6ms\n",
      "Speed: 3.1ms preprocess, 173.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 146.1ms\n",
      "Speed: 2.4ms preprocess, 146.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 158.8ms\n",
      "Speed: 2.9ms preprocess, 158.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 132.5ms\n",
      "Speed: 2.9ms preprocess, 132.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 138.7ms\n",
      "Speed: 2.5ms preprocess, 138.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 113.0ms\n",
      "Speed: 2.6ms preprocess, 113.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 149.5ms\n",
      "Speed: 3.2ms preprocess, 149.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 135.3ms\n",
      "Speed: 2.4ms preprocess, 135.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 165.2ms\n",
      "Speed: 2.8ms preprocess, 165.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 170.1ms\n",
      "Speed: 3.4ms preprocess, 170.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 152.9ms\n",
      "Speed: 4.5ms preprocess, 152.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 121.2ms\n",
      "Speed: 2.5ms preprocess, 121.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 179.0ms\n",
      "Speed: 3.2ms preprocess, 179.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 186.7ms\n",
      "Speed: 4.5ms preprocess, 186.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 176.5ms\n",
      "Speed: 3.5ms preprocess, 176.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 179.9ms\n",
      "Speed: 4.3ms preprocess, 179.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 172.9ms\n",
      "Speed: 3.3ms preprocess, 172.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 179.6ms\n",
      "Speed: 4.3ms preprocess, 179.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 153.7ms\n",
      "Speed: 3.1ms preprocess, 153.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 163.3ms\n",
      "Speed: 4.2ms preprocess, 163.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 185.7ms\n",
      "Speed: 2.4ms preprocess, 185.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 182.4ms\n",
      "Speed: 3.7ms preprocess, 182.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 171.7ms\n",
      "Speed: 3.9ms preprocess, 171.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 148.7ms\n",
      "Speed: 3.3ms preprocess, 148.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 167.8ms\n",
      "Speed: 3.9ms preprocess, 167.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 170.0ms\n",
      "Speed: 3.1ms preprocess, 170.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 184.2ms\n",
      "Speed: 3.6ms preprocess, 184.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 177.6ms\n",
      "Speed: 3.4ms preprocess, 177.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 187.2ms\n",
      "Speed: 3.4ms preprocess, 187.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 169.9ms\n",
      "Speed: 4.8ms preprocess, 169.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 178.5ms\n",
      "Speed: 3.5ms preprocess, 178.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 187.0ms\n",
      "Speed: 3.2ms preprocess, 187.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 183.9ms\n",
      "Speed: 3.4ms preprocess, 183.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 153.1ms\n",
      "Speed: 3.9ms preprocess, 153.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 141.6ms\n",
      "Speed: 2.7ms preprocess, 141.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 115.5ms\n",
      "Speed: 2.2ms preprocess, 115.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 144.5ms\n",
      "Speed: 57.6ms preprocess, 144.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 141.3ms\n",
      "Speed: 2.7ms preprocess, 141.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 119.8ms\n",
      "Speed: 2.0ms preprocess, 119.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 109.2ms\n",
      "Speed: 1.6ms preprocess, 109.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 106.5ms\n",
      "Speed: 2.5ms preprocess, 106.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 110.9ms\n",
      "Speed: 2.3ms preprocess, 110.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 114.4ms\n",
      "Speed: 3.0ms preprocess, 114.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 142.1ms\n",
      "Speed: 3.0ms preprocess, 142.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 153.4ms\n",
      "Speed: 4.9ms preprocess, 153.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 131.5ms\n",
      "Speed: 2.1ms preprocess, 131.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 120.0ms\n",
      "Speed: 2.7ms preprocess, 120.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 137.2ms\n",
      "Speed: 3.0ms preprocess, 137.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 160.4ms\n",
      "Speed: 3.7ms preprocess, 160.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 170.8ms\n",
      "Speed: 2.9ms preprocess, 170.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 167.2ms\n",
      "Speed: 3.0ms preprocess, 167.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 162.2ms\n",
      "Speed: 2.4ms preprocess, 162.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 147.7ms\n",
      "Speed: 2.8ms preprocess, 147.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 147.4ms\n",
      "Speed: 2.8ms preprocess, 147.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 152.7ms\n",
      "Speed: 2.9ms preprocess, 152.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 164.5ms\n",
      "Speed: 2.1ms preprocess, 164.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 169.4ms\n",
      "Speed: 4.1ms preprocess, 169.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 177.2ms\n",
      "Speed: 4.3ms preprocess, 177.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 182.1ms\n",
      "Speed: 3.2ms preprocess, 182.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 202.6ms\n",
      "Speed: 3.2ms preprocess, 202.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 169.8ms\n",
      "Speed: 3.1ms preprocess, 169.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 170.6ms\n",
      "Speed: 3.4ms preprocess, 170.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 168.5ms\n",
      "Speed: 3.1ms preprocess, 168.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 176.3ms\n",
      "Speed: 4.1ms preprocess, 176.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 188.7ms\n",
      "Speed: 3.0ms preprocess, 188.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 185.6ms\n",
      "Speed: 3.2ms preprocess, 185.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 179.8ms\n",
      "Speed: 3.3ms preprocess, 179.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 186.1ms\n",
      "Speed: 3.9ms preprocess, 186.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Exiting program.\n"
     ]
    }
   ],
   "source": [
    "# with standardard thresholds\n",
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "\n",
    "# --- Configuration ---\n",
    "# URL for your IP camera's RTSP stream.\n",
    "# Replace with your actual camera URL.\n",
    "IP_CAMERA_URL = \"rtsp://admin:cctv@121@192.168.1.65:554/Streaming/Channels/101\"\n",
    "\n",
    "# Path to your downloaded YOLO model\n",
    "YOLO_MODEL_PATH = \"yolov8n-face-lindevs.pt\"\n",
    "\n",
    "# Path to the folder containing known faces\n",
    "DATASET_PATH = \"dataset/\"\n",
    "\n",
    "# --- Thresholds and Settings ---\n",
    "# ** PRODUCT RECOMMENDATION **\n",
    "# A higher confidence reduces false detections of non-face objects. 0.7 is a good balance.\n",
    "YOLO_CONF_THRESHOLD = 0.7\n",
    "# ** PRODUCT RECOMMENDATION **\n",
    "# This threshold balances security and convenience. It's stricter than the ArcFace\n",
    "# default (0.68) to prevent false matches, but more lenient than 0.5 to avoid\n",
    "# rejecting authorized users under slightly different conditions (e.g., lighting, glasses).\n",
    "DEEPFACE_DISTANCE_THRESHOLD = 0.6\n",
    "WINDOW_NAME = \"IP Camera Attendance System\"\n",
    "\n",
    "# --- Performance Optimization ---\n",
    "PROCESS_EVERY_N_FRAMES = 5 \n",
    "\n",
    "# --- Reconnection Logic ---\n",
    "RECONNECT_DELAY_SECONDS = 5 # How many seconds to wait before trying to reconnect\n",
    "\n",
    "# Load YOLO model\n",
    "try:\n",
    "    model = YOLO(YOLO_MODEL_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLO model: {e}\")\n",
    "    exit()\n",
    "\n",
    "def mark_attendance(name, yolo_confidence, deepface_distance):\n",
    "    \"\"\"\n",
    "    Records a person's attendance in a CSV file, now including YOLO confidence\n",
    "    and DeepFace distance scores.\n",
    "    \"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime(\"%Y-%m-%d\")\n",
    "    time_str = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    csv_file = \"attendance.csv\"\n",
    "    # Define the new columns for the CSV file\n",
    "    csv_columns = [\"Name\", \"Date\", \"Time\", \"YOLO_Confidence\", \"DeepFace_Distance\"]\n",
    "    \n",
    "    # Create the CSV with the new headers if it doesn't exist\n",
    "    if not os.path.exists(csv_file):\n",
    "        df = pd.DataFrame(columns=csv_columns)\n",
    "        df.to_csv(csv_file, index=False)\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # --- Time-based Check Logic ---\n",
    "    marked_recently = False\n",
    "    if not df.empty:\n",
    "        # We need to handle cases where old CSVs might not have the Timestamp data\n",
    "        if 'Date' in df.columns and 'Time' in df.columns:\n",
    "            df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], errors='coerce')\n",
    "            five_minutes_ago = now - datetime.timedelta(minutes=5)\n",
    "            marked_recently = not df[(df['Name'] == name) & (df['Timestamp'] > five_minutes_ago)].empty\n",
    "\n",
    "    if not marked_recently:\n",
    "        # Format scores to 2 decimal places for cleaner output\n",
    "        yolo_conf_str = f\"{yolo_confidence:.2f}\"\n",
    "        deepface_dist_str = f\"{deepface_distance:.2f}\"\n",
    "        \n",
    "        new_entry = pd.DataFrame(\n",
    "            [[name, date, time_str, yolo_conf_str, deepface_dist_str]],\n",
    "            columns=csv_columns\n",
    "        )\n",
    "\n",
    "        # Drop the temporary Timestamp column if it exists before concatenating\n",
    "        df_updated = pd.concat([df.drop(columns=['Timestamp'], errors='ignore'), new_entry], ignore_index=True)\n",
    "        df_updated.to_csv(csv_file, index=False)\n",
    "        print(f\"✅ Attendance Marked: {name} at {time_str} (YOLO: {yolo_conf_str}, DeepFace: {deepface_dist_str})\")\n",
    "\n",
    "# Create a resizable window\n",
    "cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(WINDOW_NAME, 1280, 720)\n",
    "\n",
    "# --- Main Loop ---\n",
    "# cap = cv2.VideoCapture(IP_CAMERA_URL)\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "frame_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # --- Automatic Reconnection Logic ---\n",
    "    if not ret:\n",
    "        print(\"❌ Frame not received. Attempting to reconnect...\")\n",
    "        cap.release()\n",
    "        time.sleep(RECONNECT_DELAY_SECONDS)\n",
    "        cap = cv2.VideoCapture(IP_CAMERA_URL)\n",
    "        if not cap.isOpened():\n",
    "            print(\"❌ Failed to reconnect.\")\n",
    "            time.sleep(RECONNECT_DELAY_SECONDS)\n",
    "        else:\n",
    "            print(\"✅ Reconnected successfully!\")\n",
    "        continue\n",
    "\n",
    "    frame_counter += 1\n",
    "    \n",
    "    if frame_counter % PROCESS_EVERY_N_FRAMES == 0:\n",
    "        try:\n",
    "            process_frame = cv2.resize(frame, (640, 360))\n",
    "            results = model(process_frame, conf=YOLO_CONF_THRESHOLD)\n",
    "\n",
    "            for r in results:\n",
    "                # Iterate over each box object to access all its properties\n",
    "                for box in r.boxes:\n",
    "                    # Get the confidence score for this specific detection\n",
    "                    yolo_confidence = box.conf.item() # .item() extracts the float value\n",
    "                    \n",
    "                    # Get coordinates\n",
    "                    x1_s, y1_s, x2_s, y2_s = map(int, box.xyxy[0].cpu().numpy())\n",
    "                    \n",
    "                    # Scale coordinates back to original frame size\n",
    "                    h_orig, w_orig = frame.shape[:2]\n",
    "                    h_proc, w_proc = process_frame.shape[:2]\n",
    "                    x1 = int(x1_s * w_orig / w_proc)\n",
    "                    y1 = int(y1_s * h_orig / h_proc)\n",
    "                    x2 = int(x2_s * w_orig / w_proc)\n",
    "                    y2 = int(y2_s * h_orig / h_proc)\n",
    "                    \n",
    "                    face = frame[y1:y2, x1:x2]\n",
    "                    if face.size == 0:\n",
    "                        continue\n",
    "\n",
    "                    result_df_list = DeepFace.find(img_path=face,\n",
    "                                                   db_path=DATASET_PATH,\n",
    "                                                   model_name=\"ArcFace\",\n",
    "                                                   enforce_detection=False,\n",
    "                                                   silent=True)\n",
    "\n",
    "                    if result_df_list and not result_df_list[0].empty:\n",
    "                        best_match = result_df_list[0].iloc[0]\n",
    "                        distance = best_match['distance']\n",
    "\n",
    "                        if distance < DEEPFACE_DISTANCE_THRESHOLD:\n",
    "                            identity_path = best_match['identity']\n",
    "                            name = os.path.basename(os.path.dirname(identity_path))\n",
    "                            \n",
    "                            # *** PASS THE SCORES TO THE FUNCTION ***\n",
    "                            mark_attendance(name, yolo_confidence, distance)\n",
    "                            \n",
    "                            # Draw green box and name for recognized person\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                            cv2.putText(frame, name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                        else:\n",
    "                            # Draw red box and \"Unknown\"\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                            cv2.putText(frame, \"Unknown\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                    else:\n",
    "                        # Draw blue box if face detected but no match found in DB\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during processing: {e}\")\n",
    "\n",
    "    cv2.imshow(WINDOW_NAME, frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Exiting program.\")\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb480513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 face, 140.3ms\n",
      "Speed: 54.4ms preprocess, 140.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "📸 Saved unknown face to unknown_faces/unknown_20250925_191350.jpg\n",
      "\n",
      "0: 384x640 1 face, 105.0ms\n",
      "Speed: 1.9ms preprocess, 105.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 112.9ms\n",
      "Speed: 1.4ms preprocess, 112.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 100.7ms\n",
      "Speed: 1.6ms preprocess, 100.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 97.3ms\n",
      "Speed: 1.6ms preprocess, 97.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 102.0ms\n",
      "Speed: 1.7ms preprocess, 102.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 95.0ms\n",
      "Speed: 2.0ms preprocess, 95.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 98.2ms\n",
      "Speed: 1.8ms preprocess, 98.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 94.5ms\n",
      "Speed: 1.9ms preprocess, 94.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 123.2ms\n",
      "Speed: 1.7ms preprocess, 123.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 115.5ms\n",
      "Speed: 2.1ms preprocess, 115.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 117.4ms\n",
      "Speed: 2.0ms preprocess, 117.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 117.6ms\n",
      "Speed: 2.0ms preprocess, 117.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 115.1ms\n",
      "Speed: 1.8ms preprocess, 115.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 113.2ms\n",
      "Speed: 2.0ms preprocess, 113.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 136.2ms\n",
      "Speed: 2.2ms preprocess, 136.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 138.2ms\n",
      "Speed: 4.1ms preprocess, 138.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 138.5ms\n",
      "Speed: 3.1ms preprocess, 138.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 136.1ms\n",
      "Speed: 2.6ms preprocess, 136.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 136.0ms\n",
      "Speed: 3.2ms preprocess, 136.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 127.6ms\n",
      "Speed: 2.7ms preprocess, 127.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 112.8ms\n",
      "Speed: 2.1ms preprocess, 112.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 108.7ms\n",
      "Speed: 2.4ms preprocess, 108.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 116.1ms\n",
      "Speed: 2.1ms preprocess, 116.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.2ms\n",
      "Speed: 2.6ms preprocess, 91.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 93.9ms\n",
      "Speed: 1.9ms preprocess, 93.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 107.1ms\n",
      "Speed: 3.1ms preprocess, 107.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.0ms\n",
      "Speed: 2.1ms preprocess, 91.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.3ms\n",
      "Speed: 2.4ms preprocess, 95.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.0ms\n",
      "Speed: 2.3ms preprocess, 95.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 98.1ms\n",
      "Speed: 2.8ms preprocess, 98.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 102.5ms\n",
      "Speed: 5.0ms preprocess, 102.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 103.9ms\n",
      "Speed: 5.0ms preprocess, 103.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 106.6ms\n",
      "Speed: 5.2ms preprocess, 106.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 104.5ms\n",
      "Speed: 5.2ms preprocess, 104.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 104.7ms\n",
      "Speed: 4.4ms preprocess, 104.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 103.5ms\n",
      "Speed: 6.2ms preprocess, 103.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 81.6ms\n",
      "Speed: 4.7ms preprocess, 81.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 104.6ms\n",
      "Speed: 4.7ms preprocess, 104.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 88.1ms\n",
      "Speed: 4.6ms preprocess, 88.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 82.9ms\n",
      "Speed: 4.5ms preprocess, 82.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 95.8ms\n",
      "Speed: 4.2ms preprocess, 95.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 109.1ms\n",
      "Speed: 5.6ms preprocess, 109.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 96.8ms\n",
      "Speed: 6.4ms preprocess, 96.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 83.3ms\n",
      "Speed: 5.0ms preprocess, 83.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 98.1ms\n",
      "Speed: 5.7ms preprocess, 98.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 104.3ms\n",
      "Speed: 4.9ms preprocess, 104.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 101.2ms\n",
      "Speed: 4.4ms preprocess, 101.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 97.1ms\n",
      "Speed: 5.6ms preprocess, 97.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 98.7ms\n",
      "Speed: 4.6ms preprocess, 98.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 103.8ms\n",
      "Speed: 7.2ms preprocess, 103.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 97.5ms\n",
      "Speed: 1.6ms preprocess, 97.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 102.7ms\n",
      "Speed: 2.7ms preprocess, 102.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 99.6ms\n",
      "Speed: 1.9ms preprocess, 99.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 104.5ms\n",
      "Speed: 2.0ms preprocess, 104.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 106.6ms\n",
      "Speed: 2.6ms preprocess, 106.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 127.9ms\n",
      "Speed: 46.5ms preprocess, 127.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 128.3ms\n",
      "Speed: 2.2ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.4ms\n",
      "Speed: 2.4ms preprocess, 122.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 115.1ms\n",
      "Speed: 2.6ms preprocess, 115.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 115.5ms\n",
      "Speed: 2.5ms preprocess, 115.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 111.2ms\n",
      "Speed: 3.1ms preprocess, 111.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 105.3ms\n",
      "Speed: 2.3ms preprocess, 105.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 101.8ms\n",
      "Speed: 2.0ms preprocess, 101.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 102.8ms\n",
      "Speed: 2.0ms preprocess, 102.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 101.9ms\n",
      "Speed: 1.9ms preprocess, 101.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 109.6ms\n",
      "Speed: 3.1ms preprocess, 109.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 128.3ms\n",
      "Speed: 2.2ms preprocess, 128.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 115.6ms\n",
      "Speed: 2.4ms preprocess, 115.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 139.6ms\n",
      "Speed: 2.3ms preprocess, 139.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 134.3ms\n",
      "Speed: 2.7ms preprocess, 134.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 141.2ms\n",
      "Speed: 2.9ms preprocess, 141.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 151.4ms\n",
      "Speed: 3.6ms preprocess, 151.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 138.9ms\n",
      "Speed: 3.2ms preprocess, 138.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "📸 Saved unknown face to unknown_faces/unknown_20250925_191429.jpg\n",
      "\n",
      "0: 384x640 1 face, 151.2ms\n",
      "Speed: 2.4ms preprocess, 151.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 156.6ms\n",
      "Speed: 2.5ms preprocess, 156.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 152.7ms\n",
      "Speed: 2.5ms preprocess, 152.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 135.3ms\n",
      "Speed: 2.5ms preprocess, 135.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 109.7ms\n",
      "Speed: 5.5ms preprocess, 109.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 102.3ms\n",
      "Speed: 4.3ms preprocess, 102.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Exiting program.\n"
     ]
    }
   ],
   "source": [
    "# with standardard thresholds\n",
    "# MODIFIED: Added time module for cooldown timer\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "\n",
    "# --- Configuration ---\n",
    "# URL for your IP camera's RTSP stream.\n",
    "# Replace with your actual camera URL.\n",
    "IP_CAMERA_URL = \"rtsp://admin:cctv@121@192.168.1.65:554/Streaming/Channels/101\"\n",
    "\n",
    "# Path to your downloaded YOLO model\n",
    "YOLO_MODEL_PATH = \"yolov8n-face-lindevs.pt\"\n",
    "\n",
    "# Path to the folder containing known faces\n",
    "DATASET_PATH = \"dataset/\"\n",
    "\n",
    "# --- NEW: Configuration for saving unknown faces ---\n",
    "# The folder where images of unknown people will be saved.\n",
    "UNKNOWN_FACES_PATH = \"unknown_faces/\"\n",
    "# Cooldown in seconds to prevent saving the same unknown person multiple times.\n",
    "UNKNOWN_CAPTURE_COOLDOWN = 10.0 # seconds\n",
    "\n",
    "# --- Thresholds and Settings ---\n",
    "# ** PRODUCT RECOMMENDATION **\n",
    "# A higher confidence reduces false detections of non-face objects. 0.7 is a good balance.\n",
    "YOLO_CONF_THRESHOLD = 0.7\n",
    "# ** PRODUCT RECOMMENDATION **\n",
    "# This threshold balances security and convenience. It's stricter than the ArcFace\n",
    "# default (0.68) to prevent false matches, but more lenient than 0.5 to avoid\n",
    "# rejecting authorized users under slightly different conditions (e.g., lighting, glasses).\n",
    "DEEPFACE_DISTANCE_THRESHOLD = 0.6\n",
    "WINDOW_NAME = \"IP Camera Attendance System\"\n",
    "\n",
    "# --- Performance Optimization ---\n",
    "PROCESS_EVERY_N_FRAMES = 5\n",
    "\n",
    "# --- Reconnection Logic ---\n",
    "RECONNECT_DELAY_SECONDS = 5 # How many seconds to wait before trying to reconnect\n",
    "\n",
    "# --- NEW: Create the directory for unknown faces if it doesn't exist ---\n",
    "if not os.path.exists(UNKNOWN_FACES_PATH):\n",
    "    os.makedirs(UNKNOWN_FACES_PATH)\n",
    "    print(f\"Created directory for unknown faces at: {UNKNOWN_FACES_PATH}\")\n",
    "\n",
    "# Load YOLO model\n",
    "try:\n",
    "    model = YOLO(YOLO_MODEL_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLO model: {e}\")\n",
    "    exit()\n",
    "\n",
    "def mark_attendance(name, yolo_confidence, deepface_distance):\n",
    "    \"\"\"\n",
    "    Records a person's attendance in a CSV file, now including YOLO confidence\n",
    "    and DeepFace distance scores.\n",
    "    \"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime(\"%Y-%m-%d\")\n",
    "    time_str = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    csv_file = \"attendance.csv\"\n",
    "    # Define the new columns for the CSV file\n",
    "    csv_columns = [\"Name\", \"Date\", \"Time\", \"YOLO_Confidence\", \"DeepFace_Distance\"]\n",
    "\n",
    "    # Create the CSV with the new headers if it doesn't exist\n",
    "    if not os.path.exists(csv_file):\n",
    "        df = pd.DataFrame(columns=csv_columns)\n",
    "        df.to_csv(csv_file, index=False)\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # --- Time-based Check Logic ---\n",
    "    marked_recently = False\n",
    "    if not df.empty:\n",
    "        # We need to handle cases where old CSVs might not have the Timestamp data\n",
    "        if 'Date' in df.columns and 'Time' in df.columns:\n",
    "            df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], errors='coerce')\n",
    "            five_minutes_ago = now - datetime.timedelta(minutes=5)\n",
    "            marked_recently = not df[(df['Name'] == name) & (df['Timestamp'] > five_minutes_ago)].empty\n",
    "\n",
    "    if not marked_recently:\n",
    "        # Format scores to 2 decimal places for cleaner output\n",
    "        yolo_conf_str = f\"{yolo_confidence:.2f}\"\n",
    "        deepface_dist_str = f\"{deepface_distance:.2f}\"\n",
    "\n",
    "        new_entry = pd.DataFrame(\n",
    "            [[name, date, time_str, yolo_conf_str, deepface_dist_str]],\n",
    "            columns=csv_columns\n",
    "        )\n",
    "\n",
    "        # Drop the temporary Timestamp column if it exists before concatenating\n",
    "        df_updated = pd.concat([df.drop(columns=['Timestamp'], errors='ignore'), new_entry], ignore_index=True)\n",
    "        df_updated.to_csv(csv_file, index=False)\n",
    "        print(f\"✅ Attendance Marked: {name} at {time_str} (YOLO: {yolo_conf_str}, DeepFace: {deepface_dist_str})\")\n",
    "\n",
    "# Create a resizable window\n",
    "cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(WINDOW_NAME, 1280, 720)\n",
    "\n",
    "# --- Main Loop ---\n",
    "# cap = cv2.VideoCapture(IP_CAMERA_URL)\n",
    "cap = cv2.VideoCapture(0) # Using webcam for easier testing\n",
    "\n",
    "frame_counter = 0\n",
    "\n",
    "# --- NEW: Variable to track when the last unknown face was captured ---\n",
    "last_unknown_capture_time = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # --- Automatic Reconnection Logic ---\n",
    "    if not ret:\n",
    "        print(\"❌ Frame not received. Attempting to reconnect...\")\n",
    "        cap.release()\n",
    "        time.sleep(RECONNECT_DELAY_SECONDS)\n",
    "        cap = cv2.VideoCapture(IP_CAMERA_URL)\n",
    "        if not cap.isOpened():\n",
    "            print(\"❌ Failed to reconnect.\")\n",
    "            time.sleep(RECONNECT_DELAY_SECONDS)\n",
    "        else:\n",
    "            print(\"✅ Reconnected successfully!\")\n",
    "        continue\n",
    "\n",
    "    frame_counter += 1\n",
    "\n",
    "    if frame_counter % PROCESS_EVERY_N_FRAMES == 0:\n",
    "        try:\n",
    "            process_frame = cv2.resize(frame, (640, 360))\n",
    "            results = model(process_frame, conf=YOLO_CONF_THRESHOLD)\n",
    "\n",
    "            for r in results:\n",
    "                # Iterate over each box object to access all its properties\n",
    "                for box in r.boxes:\n",
    "                    # Get the confidence score for this specific detection\n",
    "                    yolo_confidence = box.conf.item() # .item() extracts the float value\n",
    "\n",
    "                    # Get coordinates\n",
    "                    x1_s, y1_s, x2_s, y2_s = map(int, box.xyxy[0].cpu().numpy())\n",
    "\n",
    "                    # Scale coordinates back to original frame size\n",
    "                    h_orig, w_orig = frame.shape[:2]\n",
    "                    h_proc, w_proc = process_frame.shape[:2]\n",
    "                    x1 = int(x1_s * w_orig / w_proc)\n",
    "                    y1 = int(y1_s * h_orig / h_proc)\n",
    "                    x2 = int(x2_s * w_orig / w_proc)\n",
    "                    y2 = int(y2_s * h_orig / h_proc)\n",
    "\n",
    "                    face = frame[y1:y2, x1:x2]\n",
    "                    if face.size == 0:\n",
    "                        continue\n",
    "\n",
    "                    result_df_list = DeepFace.find(img_path=face,\n",
    "                                                   db_path=DATASET_PATH,\n",
    "                                                   model_name=\"ArcFace\",\n",
    "                                                   enforce_detection=False,\n",
    "                                                   silent=True)\n",
    "\n",
    "                    if result_df_list and not result_df_list[0].empty:\n",
    "                        best_match = result_df_list[0].iloc[0]\n",
    "                        distance = best_match['distance']\n",
    "\n",
    "                        if distance < DEEPFACE_DISTANCE_THRESHOLD:\n",
    "                            identity_path = best_match['identity']\n",
    "                            name = os.path.basename(os.path.dirname(identity_path))\n",
    "\n",
    "                            # *** PASS THE SCORES TO THE FUNCTION ***\n",
    "                            mark_attendance(name, yolo_confidence, distance)\n",
    "\n",
    "                            # Draw green box and name for recognized person\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                            cv2.putText(frame, name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                        else:\n",
    "                            # Draw red box and \"Unknown\"\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                            cv2.putText(frame, \"Unknown\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                            \n",
    "                            # --- NEW: Save unknown face image with cooldown ---\n",
    "                            current_time = time.time()\n",
    "                            if (current_time - last_unknown_capture_time) > UNKNOWN_CAPTURE_COOLDOWN:\n",
    "                                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                                filename = f\"unknown_{timestamp}.jpg\"\n",
    "                                filepath = os.path.join(UNKNOWN_FACES_PATH, filename)\n",
    "                                cv2.imwrite(filepath, face)\n",
    "                                print(f\"📸 Saved unknown face to {filepath}\")\n",
    "                                last_unknown_capture_time = current_time\n",
    "                    else:\n",
    "                        # Draw blue box if face detected but no match found in DB\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                        \n",
    "                        # --- NEW: Save unknown face image with cooldown (also for this case) ---\n",
    "                        current_time = time.time()\n",
    "                        if (current_time - last_unknown_capture_time) > UNKNOWN_CAPTURE_COOLDOWN:\n",
    "                            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                            filename = f\"unknown_{timestamp}.jpg\"\n",
    "                            filepath = os.path.join(UNKNOWN_FACES_PATH, filename)\n",
    "                            cv2.imwrite(filepath, face)\n",
    "                            print(f\"📸 Saved unknown face to {filepath}\")\n",
    "                            last_unknown_capture_time = current_time\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during processing: {e}\")\n",
    "\n",
    "    cv2.imshow(WINDOW_NAME, frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Exiting program.\")\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77993b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with standardard thresholds\n",
    "# MODIFIED: Added time module for cooldown timer\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "\n",
    "# --- Configuration ---\n",
    "# URL for your IP camera's RTSP stream.\n",
    "# Replace with your actual camera URL.\n",
    "IP_CAMERA_URL = \"rtsp://admin:cctv@121@192.168.1.65:554/Streaming/Channels/101\"\n",
    "\n",
    "# Path to your downloaded YOLO model\n",
    "YOLO_MODEL_PATH = \"yolov8n-face-lindevs.pt\"\n",
    "\n",
    "# Path to the folder containing known faces\n",
    "DATASET_PATH = \"dataset/\"\n",
    "\n",
    "# --- NEW: Configuration for saving unknown faces ---\n",
    "# The folder where images of unknown people will be saved.\n",
    "UNKNOWN_FACES_PATH = \"unknown_faces/\"\n",
    "# Cooldown in seconds to prevent saving the same unknown person multiple times.\n",
    "UNKNOWN_CAPTURE_COOLDOWN = 10.0 # seconds\n",
    "\n",
    "# --- Thresholds and Settings ---\n",
    "# ** PRODUCT RECOMMENDATION **\n",
    "# A higher confidence reduces false detections of non-face objects. 0.7 is a good balance.\n",
    "YOLO_CONF_THRESHOLD = 0.7\n",
    "# ** PRODUCT RECOMMENDATION **\n",
    "# This threshold balances security and convenience. It's stricter than the ArcFace\n",
    "# default (0.68) to prevent false matches, but more lenient than 0.5 to avoid\n",
    "# rejecting authorized users under slightly different conditions (e.g., lighting, glasses).\n",
    "DEEPFACE_DISTANCE_THRESHOLD = 0.6\n",
    "WINDOW_NAME = \"IP Camera Attendance System\"\n",
    "\n",
    "# --- Performance Optimization ---\n",
    "PROCESS_EVERY_N_FRAMES = 5\n",
    "\n",
    "# --- Reconnection Logic ---\n",
    "RECONNECT_DELAY_SECONDS = 5 # How many seconds to wait before trying to reconnect\n",
    "\n",
    "#--- Thresholds and Settings ---\n",
    "# NEW: Add padding in pixels to the face crop to make space for the timestamp\n",
    "PADDING = 40 \n",
    "\n",
    "# --- NEW: Create the directory for unknown faces if it doesn't exist ---\n",
    "if not os.path.exists(UNKNOWN_FACES_PATH):\n",
    "    os.makedirs(UNKNOWN_FACES_PATH)\n",
    "    print(f\"Created directory for unknown faces at: {UNKNOWN_FACES_PATH}\")\n",
    "\n",
    "\n",
    "    from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Load YOLO model\n",
    "try:\n",
    "    model = YOLO(YOLO_MODEL_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLO model: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mark_attendance(name, yolo_confidence, deepface_distance):\n",
    "    \"\"\"\n",
    "    Records a person's attendance in a CSV file, now including YOLO confidence\n",
    "    and DeepFace distance scores.\n",
    "    \"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime(\"%Y-%m-%d\")\n",
    "    time_str = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    csv_file = \"attendance.csv\"\n",
    "    # Define the new columns for the CSV file\n",
    "    csv_columns = [\"Name\", \"Date\", \"Time\", \"YOLO_Confidence\", \"DeepFace_Distance\"]\n",
    "\n",
    "    # Create the CSV with the new headers if it doesn't exist\n",
    "    if not os.path.exists(csv_file):\n",
    "        df = pd.DataFrame(columns=csv_columns)\n",
    "        df.to_csv(csv_file, index=False)\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # --- Time-based Check Logic ---\n",
    "    marked_recently = False\n",
    "    if not df.empty:\n",
    "        # We need to handle cases where old CSVs might not have the Timestamp data\n",
    "        if 'Date' in df.columns and 'Time' in df.columns:\n",
    "            df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], errors='coerce')\n",
    "            five_minutes_ago = now - datetime.timedelta(minutes=5)\n",
    "            marked_recently = not df[(df['Name'] == name) & (df['Timestamp'] > five_minutes_ago)].empty\n",
    "\n",
    "    if not marked_recently:\n",
    "        # Format scores to 2 decimal places for cleaner output\n",
    "        yolo_conf_str = f\"{yolo_confidence:.2f}\"\n",
    "        deepface_dist_str = f\"{deepface_distance:.2f}\"\n",
    "\n",
    "        new_entry = pd.DataFrame(\n",
    "            [[name, date, time_str, yolo_conf_str, deepface_dist_str]],\n",
    "            columns=csv_columns\n",
    "        )\n",
    "\n",
    "        # Drop the temporary Timestamp column if it exists before concatenating\n",
    "        df_updated = pd.concat([df.drop(columns=['Timestamp'], errors='ignore'), new_entry], ignore_index=True)\n",
    "        df_updated.to_csv(csv_file, index=False)\n",
    "        print(f\"✅ Attendance Marked: {name} at {time_str} (YOLO: {yolo_conf_str}, DeepFace: {deepface_dist_str})\")\n",
    "\n",
    "# Create a resizable window\n",
    "cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(WINDOW_NAME, 640, 320)\n",
    "\n",
    "# --- Main Loop ---\n",
    "# cap = cv2.VideoCapture(IP_CAMERA_URL)\n",
    "cap = cv2.VideoCapture(1) # Using webcam for easier testing\n",
    "\n",
    "frame_counter = 0\n",
    "\n",
    "# --- NEW: Variable to track when the last unknown face was captured ---\n",
    "last_unknown_capture_time = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # --- Automatic Reconnection Logic ---\n",
    "    if not ret:\n",
    "        print(\"❌ Frame not received. Attempting to reconnect...\")\n",
    "        cap.release()\n",
    "        time.sleep(RECONNECT_DELAY_SECONDS)\n",
    "        cap = cv2.VideoCapture(IP_CAMERA_URL)\n",
    "        if not cap.isOpened():\n",
    "            print(\"❌ Failed to reconnect.\")\n",
    "            time.sleep(RECONNECT_DELAY_SECONDS)\n",
    "        else:\n",
    "            print(\"✅ Reconnected successfully!\")\n",
    "        continue\n",
    "\n",
    "    frame_counter += 1\n",
    "\n",
    "    if frame_counter % PROCESS_EVERY_N_FRAMES == 0:\n",
    "        try:\n",
    "            process_frame = cv2.resize(frame, (640, 360))\n",
    "            results = model(process_frame, conf=YOLO_CONF_THRESHOLD)\n",
    "\n",
    "            for r in results:\n",
    "                # Iterate over each box object to access all its properties\n",
    "                for box in r.boxes:\n",
    "                    # Get the confidence score for this specific detection\n",
    "                    yolo_confidence = box.conf.item() # .item() extracts the float value\n",
    "\n",
    "                    # Get coordinates\n",
    "                    x1_s, y1_s, x2_s, y2_s = map(int, box.xyxy[0].cpu().numpy())\n",
    "\n",
    "                    # # Scale coordinates back to original frame size\n",
    "                    # h_orig, w_orig = frame.shape[:2]\n",
    "                    # h_proc, w_proc = process_frame.shape[:2]\n",
    "                    # x1 = int(x1_s * w_orig / w_proc)\n",
    "                    # y1 = int(y1_s * h_orig / h_proc)\n",
    "                    # x2 = int(x2_s * w_orig / w_proc)\n",
    "                    # y2 = int(y2_s * h_orig / h_proc)\n",
    "\n",
    "                    # ... inside the `for box in r.boxes:` loop ...\n",
    "\n",
    "                    # Scale coordinates back to original frame size\n",
    "                    h_orig, w_orig = frame.shape[:2]\n",
    "                    h_proc, w_proc = process_frame.shape[:2]\n",
    "                    x1 = int(x1_s * w_orig / w_proc)\n",
    "                    y1 = int(y1_s * h_orig / h_proc)\n",
    "                    x2 = int(x2_s * w_orig / w_proc)\n",
    "                    y2 = int(y2_s * h_orig / h_proc)\n",
    "\n",
    "                    # --- MODIFICATION START: Add padding to the face crop ---\n",
    "                    # Calculate new padded coordinates, ensuring they stay within the frame boundaries\n",
    "                    pad_y1 = max(0, y1 - PADDING)\n",
    "                    pad_x1 = max(0, x1 - PADDING)\n",
    "                    pad_y2 = min(h_orig, y2 + PADDING)\n",
    "                    pad_x2 = min(w_orig, x2 + PADDING)\n",
    "                    \n",
    "                    # Crop the face using the new, padded coordinates\n",
    "                    face = frame[pad_y1:pad_y2, pad_x1:pad_x2]\n",
    "                    # --- MODIFICATION END ---\n",
    "                    \n",
    "                    if face.size == 0:\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    result_df_list = DeepFace.find(img_path=face,\n",
    "                                                   db_path=DATASET_PATH,\n",
    "                                                   model_name=\"ArcFace\",\n",
    "                                                   enforce_detection=False,\n",
    "                                                   silent=True)\n",
    "\n",
    "               \n",
    "\n",
    "                    if result_df_list and not result_df_list[0].empty:\n",
    "                        best_match = result_df_list[0].iloc[0]\n",
    "                        distance = best_match['distance']\n",
    "\n",
    "                        if distance < DEEPFACE_DISTANCE_THRESHOLD:\n",
    "                            identity_path = best_match['identity']\n",
    "                            name = os.path.basename(os.path.dirname(identity_path))\n",
    "\n",
    "                            mark_attendance(name, yolo_confidence, distance)\n",
    "\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                            cv2.putText(frame, name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                        else:\n",
    "                            # Draw red box and \"Unknown\"\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                            cv2.putText(frame, \"Unknown\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                            \n",
    "                            # --- MODIFIED: Save unknown face image with timestamp on photo ---\n",
    "                            current_time = time.time()\n",
    "                            if (current_time - last_unknown_capture_time) > UNKNOWN_CAPTURE_COOLDOWN:\n",
    "                                # Get current datetime for both filename and text on image\n",
    "                                current_datetime = datetime.datetime.now()\n",
    "                                timestamp_str_filename = current_datetime.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                                timestamp_str_display = current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                                # Create a copy of the face image to draw on\n",
    "                                face_with_timestamp = face.copy()\n",
    "                                \n",
    "                                # Add timestamp text to the copied face image\n",
    "                                # Position the text: (x, y) - x=5 pixels from left, y=20 pixels from top\n",
    "                                cv2.putText(face_with_timestamp, timestamp_str_display, (5, 20), \n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                                \n",
    "                                filename = f\"unknown_{timestamp_str_filename}.jpg\"\n",
    "                                filepath = os.path.join(UNKNOWN_FACES_PATH, filename)\n",
    "                                # Save the image with the timestamp drawn on it\n",
    "                                cv2.imwrite(filepath, face_with_timestamp) \n",
    "                                print(f\"📸 Saved unknown face with timestamp to {filepath}\")\n",
    "                                last_unknown_capture_time = current_time\n",
    "                    else:\n",
    "                        # Draw blue box if face detected but no match found in DB\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                        \n",
    "                        # --- MODIFIED: Save unknown face image with timestamp on photo (also for this case) ---\n",
    "                        current_time = time.time()\n",
    "                        if (current_time - last_unknown_capture_time) > UNKNOWN_CAPTURE_COOLDOWN:\n",
    "                            # Get current datetime for both filename and text on image\n",
    "                            current_datetime = datetime.datetime.now()\n",
    "                            timestamp_str_filename = current_datetime.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                            timestamp_str_display = current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                            # Create a copy of the face image to draw on\n",
    "                            face_with_timestamp = face.copy()\n",
    "                            \n",
    "                            # Add timestamp text to the copied face image\n",
    "                            cv2.putText(face_with_timestamp, timestamp_str_display, (5, 20), \n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                            \n",
    "                            filename = f\"unknown_{timestamp_str_filename}.jpg\"\n",
    "                            filepath = os.path.join(UNKNOWN_FACES_PATH, filename)\n",
    "                            # Save the image with the timestamp drawn on it\n",
    "                            cv2.imwrite(filepath, face_with_timestamp)\n",
    "                            print(f\"📸 Saved unknown face with timestamp to {filepath}\")\n",
    "                            last_unknown_capture_time = current_time\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during processing: {e}\")\n",
    "\n",
    "    cv2.imshow(WINDOW_NAME, frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Exiting program.\")\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f8d278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25-10-03 20:21:24 - Directory C:\\Users\\Frames/.deepface created\n",
      "25-10-03 20:21:24 - Directory C:\\Users\\Frames/.deepface/weights created\n",
      "PyTorch GPU available: False\n",
      "PyTorch GPU device: CPU\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL ultralytics.nn.tasks.DetectionModel was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ultralytics.nn.tasks.DetectionModel])` or the `torch.serialization.safe_globals([ultralytics.nn.tasks.DetectionModel])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch GPU device:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Load YOLO model on GPU explicitly\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mYOLO_MODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m model\u001b[38;5;241m.\u001b[39mfuse()  \u001b[38;5;66;03m# optional, fuse conv + bn layers for speed\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Move model to GPU if not automatically\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Frames\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py:107\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Frames\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py:156\u001b[0m, in \u001b[0;36mYOLO._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    154\u001b[0m suffix \u001b[38;5;241m=\u001b[39m Path(weights)\u001b[38;5;241m.\u001b[39msuffix\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\Frames\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ultralytics\\nn\\tasks.py:578\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    577\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 578\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m    579\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m'\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m    580\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Frames\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ultralytics\\nn\\tasks.py:518\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight)\u001b[0m\n\u001b[0;32m    516\u001b[0m file \u001b[38;5;241m=\u001b[39m attempt_download_asset(weight)  \u001b[38;5;66;03m# search online if missing locally\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, file  \u001b[38;5;66;03m# load\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Frames\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\serialization.py:1529\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1521\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1522\u001b[0m                     opened_zipfile,\n\u001b[0;32m   1523\u001b[0m                     map_location,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1526\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1527\u001b[0m                 )\n\u001b[0;32m   1528\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1529\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1531\u001b[0m             opened_zipfile,\n\u001b[0;32m   1532\u001b[0m             map_location,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1535\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1536\u001b[0m         )\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL ultralytics.nn.tasks.DetectionModel was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ultralytics.nn.tasks.DetectionModel])` or the `torch.serialization.safe_globals([ultralytics.nn.tasks.DetectionModel])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "\n",
    "# with standardard thresholds\n",
    "# MODIFIED: Added time module for cooldown timer\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "\n",
    "# --- Configuration ---\n",
    "# URL for your IP camera's RTSP stream.\n",
    "# Replace with your actual camera URL.\n",
    "IP_CAMERA_URL = \"rtsp://admin:cctv@121@192.168.1.65:554/Streaming/Channels/101\"\n",
    "\n",
    "# Path to your downloaded YOLO model\n",
    "YOLO_MODEL_PATH = \"yolov8n-face-lindevs.pt\"\n",
    "\n",
    "# Path to the folder containing known faces\n",
    "DATASET_PATH = \"dataset/\"\n",
    "\n",
    "# --- NEW: Configuration for saving unknown faces ---\n",
    "# The folder where images of unknown people will be saved.\n",
    "UNKNOWN_FACES_PATH = \"unknown_faces/\"\n",
    "# Cooldown in seconds to prevent saving the same unknown person multiple times.\n",
    "UNKNOWN_CAPTURE_COOLDOWN = 10.0 # seconds\n",
    "\n",
    "# --- Thresholds and Settings ---\n",
    "# ** PRODUCT RECOMMENDATION **\n",
    "# A higher confidence reduces false detections of non-face objects. 0.7 is a good balance.\n",
    "YOLO_CONF_THRESHOLD = 0.7\n",
    "# ** PRODUCT RECOMMENDATION **\n",
    "# This threshold balances security and convenience. It's stricter than the ArcFace\n",
    "# default (0.68) to prevent false matches, but more lenient than 0.5 to avoid\n",
    "# rejecting authorized users under slightly different conditions (e.g., lighting, glasses).\n",
    "DEEPFACE_DISTANCE_THRESHOLD = 0.6\n",
    "WINDOW_NAME = \"IP Camera Attendance System\"\n",
    "\n",
    "# --- Performance Optimization ---\n",
    "PROCESS_EVERY_N_FRAMES = 5\n",
    "\n",
    "# --- Reconnection Logic ---\n",
    "RECONNECT_DELAY_SECONDS = 5 # How many seconds to wait before trying to reconnect\n",
    "\n",
    "#--- Thresholds and Settings ---\n",
    "# NEW: Add padding in pixels to the face crop to make space for the timestamp\n",
    "PADDING = 40 \n",
    "\n",
    "# --- NEW: Create the directory for unknown faces if it doesn't exist ---\n",
    "if not os.path.exists(UNKNOWN_FACES_PATH):\n",
    "    os.makedirs(UNKNOWN_FACES_PATH)\n",
    "    print(f\"Created directory for unknown faces at: {UNKNOWN_FACES_PATH}\")\n",
    "\n",
    "\n",
    "    from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Check PyTorch GPU availability\n",
    "print(\"PyTorch GPU available:\", torch.cuda.is_available())\n",
    "print(\"PyTorch GPU device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "# Load YOLO model on GPU explicitly\n",
    "model = YOLO(YOLO_MODEL_PATH)\n",
    "model.fuse()  # optional, fuse conv + bn layers for speed\n",
    "from ultralytics.nn.tasks import DetectionModel\n",
    "# Move model to GPU if not automatically\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n",
    "\n",
    "\n",
    "    # Allowlist the DetectionModel for safe loading\n",
    "torch.serialization.add_safe_globals([DetectionModel])\n",
    "\n",
    "# # Load YOLO model\n",
    "# try:\n",
    "#     model = YOLO(YOLO_MODEL_PATH)\n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading YOLO model: {e}\")\n",
    "#     exit()\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "def mark_attendance(name, yolo_confidence, deepface_distance):\n",
    "    \"\"\"\n",
    "    Records a person's attendance in a CSV file, now including YOLO confidence\n",
    "    and DeepFace distance scores.\n",
    "    \"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime(\"%Y-%m-%d\")\n",
    "    time_str = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    csv_file = \"attendance.csv\"\n",
    "    # Define the new columns for the CSV file\n",
    "    csv_columns = [\"Name\", \"Date\", \"Time\", \"YOLO_Confidence\", \"DeepFace_Distance\"]\n",
    "\n",
    "    # Create the CSV with the new headers if it doesn't exist\n",
    "    if not os.path.exists(csv_file):\n",
    "        df = pd.DataFrame(columns=csv_columns)\n",
    "        df.to_csv(csv_file, index=False)\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # --- Time-based Check Logic ---\n",
    "    marked_recently = False\n",
    "    if not df.empty:\n",
    "        # We need to handle cases where old CSVs might not have the Timestamp data\n",
    "        if 'Date' in df.columns and 'Time' in df.columns:\n",
    "            df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], errors='coerce')\n",
    "            five_minutes_ago = now - datetime.timedelta(minutes=5)\n",
    "            marked_recently = not df[(df['Name'] == name) & (df['Timestamp'] > five_minutes_ago)].empty\n",
    "\n",
    "    if not marked_recently:\n",
    "        # Format scores to 2 decimal places for cleaner output\n",
    "        yolo_conf_str = f\"{yolo_confidence:.2f}\"\n",
    "        deepface_dist_str = f\"{deepface_distance:.2f}\"\n",
    "\n",
    "        new_entry = pd.DataFrame(\n",
    "            [[name, date, time_str, yolo_conf_str, deepface_dist_str]],\n",
    "            columns=csv_columns\n",
    "        )\n",
    "\n",
    "        # Drop the temporary Timestamp column if it exists before concatenating\n",
    "        df_updated = pd.concat([df.drop(columns=['Timestamp'], errors='ignore'), new_entry], ignore_index=True)\n",
    "        df_updated.to_csv(csv_file, index=False)\n",
    "        print(f\"✅ Attendance Marked: {name} at {time_str} (YOLO: {yolo_conf_str}, DeepFace: {deepface_dist_str})\")\n",
    "\n",
    "# Create a resizable window\n",
    "cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(WINDOW_NAME, 640, 320)\n",
    "\n",
    "# --- Main Loop ---\n",
    "# cap = cv2.VideoCapture(IP_CAMERA_URL)\n",
    "cap = cv2.VideoCapture(1) # Using webcam for easier testing\n",
    "\n",
    "frame_counter = 0\n",
    "\n",
    "# --- NEW: Variable to track when the last unknown face was captured ---\n",
    "last_unknown_capture_time = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # --- Automatic Reconnection Logic ---\n",
    "    if not ret:\n",
    "        print(\"❌ Frame not received. Attempting to reconnect...\")\n",
    "        cap.release()\n",
    "        time.sleep(RECONNECT_DELAY_SECONDS)\n",
    "        cap = cv2.VideoCapture(IP_CAMERA_URL)\n",
    "        if not cap.isOpened():\n",
    "            print(\"❌ Failed to reconnect.\")\n",
    "            time.sleep(RECONNECT_DELAY_SECONDS)\n",
    "        else:\n",
    "            print(\"✅ Reconnected successfully!\")\n",
    "        continue\n",
    "\n",
    "    frame_counter += 1\n",
    "\n",
    "    if frame_counter % PROCESS_EVERY_N_FRAMES == 0:\n",
    "        try:\n",
    "            process_frame = cv2.resize(frame, (640, 360))\n",
    "            results = model(process_frame, conf=YOLO_CONF_THRESHOLD)\n",
    "\n",
    "            for r in results:\n",
    "                # Iterate over each box object to access all its properties\n",
    "                for box in r.boxes:\n",
    "                    # Get the confidence score for this specific detection\n",
    "                    yolo_confidence = box.conf.item() # .item() extracts the float value\n",
    "\n",
    "                    # Get coordinates\n",
    "                    x1_s, y1_s, x2_s, y2_s = map(int, box.xyxy[0].cpu().numpy())\n",
    "\n",
    "                    # # Scale coordinates back to original frame size\n",
    "                    # h_orig, w_orig = frame.shape[:2]\n",
    "                    # h_proc, w_proc = process_frame.shape[:2]\n",
    "                    # x1 = int(x1_s * w_orig / w_proc)\n",
    "                    # y1 = int(y1_s * h_orig / h_proc)\n",
    "                    # x2 = int(x2_s * w_orig / w_proc)\n",
    "                    # y2 = int(y2_s * h_orig / h_proc)\n",
    "\n",
    "                    # ... inside the `for box in r.boxes:` loop ...\n",
    "\n",
    "                    # Scale coordinates back to original frame size\n",
    "                    h_orig, w_orig = frame.shape[:2]\n",
    "                    h_proc, w_proc = process_frame.shape[:2]\n",
    "                    x1 = int(x1_s * w_orig / w_proc)\n",
    "                    y1 = int(y1_s * h_orig / h_proc)\n",
    "                    x2 = int(x2_s * w_orig / w_proc)\n",
    "                    y2 = int(y2_s * h_orig / h_proc)\n",
    "\n",
    "                    # --- MODIFICATION START: Add padding to the face crop ---\n",
    "                    # Calculate new padded coordinates, ensuring they stay within the frame boundaries\n",
    "                    pad_y1 = max(0, y1 - PADDING)\n",
    "                    pad_x1 = max(0, x1 - PADDING)\n",
    "                    pad_y2 = min(h_orig, y2 + PADDING)\n",
    "                    pad_x2 = min(w_orig, x2 + PADDING)\n",
    "                    \n",
    "                    # Crop the face using the new, padded coordinates\n",
    "                    face = frame[pad_y1:pad_y2, pad_x1:pad_x2]\n",
    "                    # --- MODIFICATION END ---\n",
    "                    \n",
    "                    if face.size == 0:\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    result_df_list = DeepFace.find(img_path=face,\n",
    "                                                   db_path=DATASET_PATH,\n",
    "                                                   model_name=\"ArcFace\",\n",
    "                                                   enforce_detection=False,\n",
    "                                                   silent=True)\n",
    "\n",
    "               \n",
    "\n",
    "                    if result_df_list and not result_df_list[0].empty:\n",
    "                        best_match = result_df_list[0].iloc[0]\n",
    "                        distance = best_match['distance']\n",
    "\n",
    "                        if distance < DEEPFACE_DISTANCE_THRESHOLD:\n",
    "                            identity_path = best_match['identity']\n",
    "                            name = os.path.basename(os.path.dirname(identity_path))\n",
    "\n",
    "                            mark_attendance(name, yolo_confidence, distance)\n",
    "\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                            cv2.putText(frame, name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                        else:\n",
    "                            # Draw red box and \"Unknown\"\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                            cv2.putText(frame, \"Unknown\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                            \n",
    "                            # --- MODIFIED: Save unknown face image with timestamp on photo ---\n",
    "                            current_time = time.time()\n",
    "                            if (current_time - last_unknown_capture_time) > UNKNOWN_CAPTURE_COOLDOWN:\n",
    "                                # Get current datetime for both filename and text on image\n",
    "                                current_datetime = datetime.datetime.now()\n",
    "                                timestamp_str_filename = current_datetime.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                                timestamp_str_display = current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                                # Create a copy of the face image to draw on\n",
    "                                face_with_timestamp = face.copy()\n",
    "                                \n",
    "                                # Add timestamp text to the copied face image\n",
    "                                # Position the text: (x, y) - x=5 pixels from left, y=20 pixels from top\n",
    "                                cv2.putText(face_with_timestamp, timestamp_str_display, (5, 20), \n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                                \n",
    "                                filename = f\"unknown_{timestamp_str_filename}.jpg\"\n",
    "                                filepath = os.path.join(UNKNOWN_FACES_PATH, filename)\n",
    "                                # Save the image with the timestamp drawn on it\n",
    "                                cv2.imwrite(filepath, face_with_timestamp) \n",
    "                                print(f\"📸 Saved unknown face with timestamp to {filepath}\")\n",
    "                                last_unknown_capture_time = current_time\n",
    "                    else:\n",
    "                        # Draw blue box if face detected but no match found in DB\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                        \n",
    "                        # --- MODIFIED: Save unknown face image with timestamp on photo (also for this case) ---\n",
    "                        current_time = time.time()\n",
    "                        if (current_time - last_unknown_capture_time) > UNKNOWN_CAPTURE_COOLDOWN:\n",
    "                            # Get current datetime for both filename and text on image\n",
    "                            current_datetime = datetime.datetime.now()\n",
    "                            timestamp_str_filename = current_datetime.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                            timestamp_str_display = current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                            # Create a copy of the face image to draw on\n",
    "                            face_with_timestamp = face.copy()\n",
    "                            \n",
    "                            # Add timestamp text to the copied face image\n",
    "                            cv2.putText(face_with_timestamp, timestamp_str_display, (5, 20), \n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                            \n",
    "                            filename = f\"unknown_{timestamp_str_filename}.jpg\"\n",
    "                            filepath = os.path.join(UNKNOWN_FACES_PATH, filename)\n",
    "                            # Save the image with the timestamp drawn on it\n",
    "                            cv2.imwrite(filepath, face_with_timestamp)\n",
    "                            print(f\"📸 Saved unknown face with timestamp to {filepath}\")\n",
    "                            last_unknown_capture_time = current_time\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during processing: {e}\")\n",
    "\n",
    "    cv2.imshow(WINDOW_NAME, frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Exiting program.\")\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
