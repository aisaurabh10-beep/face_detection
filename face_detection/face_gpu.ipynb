{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258c9ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch GPU available: False\n",
      "TensorFlow GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# Deep learning libraries\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.nn.tasks import DetectionModel\n",
    "import tensorflow as tf\n",
    "from deepface import DeepFace\n",
    "\n",
    "# --- Check GPU availability ---\n",
    "print(\"PyTorch GPU available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"PyTorch GPU device:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"TensorFlow GPUs:\", gpus)\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd30e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "# --- Configuration ---\n",
    "# URL for your IP camera's RTSP stream.\n",
    "# Replace with your actual camera URL or use 0 for the default webcam.\n",
    "IP_CAMERA_URL = \"rtsp://admin:cctv@121@192.168.1.65:554/Streaming/Channels/101\"\n",
    "# IP_CAMERA_URL = 1 # Using webcam for easier testing\n",
    "\n",
    "# Path to your downloaded YOLO model\n",
    "YOLO_MODEL_PATH = \"yolov8n-face-lindevs.pt\"\n",
    "\n",
    "# Path to the folder containing known faces\n",
    "DATASET_PATH = \"dataset/\"\n",
    "\n",
    "# The folder where images of unknown people will be saved.\n",
    "UNKNOWN_FACES_PATH = \"unknown_faces/\"\n",
    "# Cooldown in seconds to prevent saving the same unknown person multiple times.\n",
    "UNKNOWN_CAPTURE_COOLDOWN = 10.0 # seconds\n",
    "\n",
    "# --- Thresholds and Settings ---\n",
    "YOLO_CONF_THRESHOLD = 0.7\n",
    "DEEPFACE_DISTANCE_THRESHOLD = 0.6\n",
    "WINDOW_NAME = \"IP Camera Attendance System\"\n",
    "PADDING = 40\n",
    "\n",
    "# --- Performance Optimization ---\n",
    "PROCESS_EVERY_N_FRAMES = 5\n",
    "\n",
    "# --- Reconnection Logic ---\n",
    "RECONNECT_DELAY_SECONDS = 5 # How many seconds to wait before trying to reconnect\n",
    "\n",
    "# --- Create the directory for unknown faces if it doesn't exist ---\n",
    "if not os.path.exists(UNKNOWN_FACES_PATH):\n",
    "    os.makedirs(UNKNOWN_FACES_PATH)\n",
    "    print(f\"Created directory for unknown faces at: {UNKNOWN_FACES_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475f0a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PyTorch is using the GPU: NVIDIA GeForce RTX 3060\n",
      "CUDA version: 12.6\n",
      "Torch version: 2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (NVIDIA GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    # If a GPU is available, get the name of the first GPU\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"‚úÖ PyTorch is using the GPU: {gpu_name}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Torch version: {torch.__version__}\")\n",
    "else:\n",
    "    print(\"‚ùå PyTorch is NOT using a GPU. It's running on the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ebfd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Camera and YOLO Detection Test ---\n",
      "Press 'q' to quit the window.\n",
      "YOLO detection test complete.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "IP_CAMERA_URL = \"rtsp://admin:cctv@121@192.168.1.65:554/Streaming/Channels/101\"\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "YOLO_MODEL_PATH = \"yolov8n-face-lindevs.pt\" # Or the correct path to your model\n",
    "YOLO_CONF_THRESHOLD = 0.7\n",
    "WINDOW_NAME = \"YOLO Face Detection Test\"\n",
    "\n",
    "# --- Setup ---\n",
    "model = YOLO(YOLO_MODEL_PATH)\n",
    "model.to('cuda') # Explicitly move the model to the GPU\n",
    "\n",
    "# --- Main Detection Loop ---\n",
    "print(\"--- Starting Camera and YOLO Detection Test ---\")\n",
    "print(\"Press 'q' to quit the window.\")\n",
    "\n",
    "# cap = cv2.VideoCapture(IP_CAMERA_URL)\n",
    "# # Change your video capture line to this:\n",
    "cap = cv2.VideoCapture(IP_CAMERA_URL, cv2.CAP_FFMPEG) # Use 0 or 1 for your webcam\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Error: Could not open video stream. Check your camera index.\")\n",
    "else:\n",
    "    cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"‚ùå No frame received. Exiting.\")\n",
    "            break\n",
    "        \n",
    "        results = model(frame, conf=YOLO_CONF_THRESHOLD, verbose=False)\n",
    "\n",
    "        for r in results:\n",
    "            for box in r.boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "                yolo_confidence = box.conf.item()\n",
    "                label = f\"Face: {yolo_confidence:.2f}\"\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow(WINDOW_NAME, frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"YOLO detection test complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb02479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch GPU available: True\n",
      "PyTorch GPU device: NVIDIA GeForce RTX 3060\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 24.4ms preprocess, 47.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 55.1ms\n",
      "Speed: 4.2ms preprocess, 55.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.8ms\n",
      "Speed: 4.5ms preprocess, 41.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.6ms\n",
      "Speed: 4.8ms preprocess, 31.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.7ms\n",
      "Speed: 4.0ms preprocess, 23.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.7ms\n",
      "Speed: 4.2ms preprocess, 123.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.5ms\n",
      "Speed: 3.4ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.5ms\n",
      "Speed: 3.4ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 20.3ms\n",
      "Speed: 3.7ms preprocess, 20.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 20.8ms\n",
      "Speed: 3.7ms preprocess, 20.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.1ms\n",
      "Speed: 3.5ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 19.4ms\n",
      "Speed: 3.4ms preprocess, 19.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.8ms\n",
      "Speed: 3.5ms preprocess, 16.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 19.9ms\n",
      "Speed: 3.5ms preprocess, 19.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.5ms\n",
      "Speed: 5.6ms preprocess, 24.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.3ms\n",
      "Speed: 4.1ms preprocess, 16.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.4ms\n",
      "Speed: 4.0ms preprocess, 15.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 53.3ms\n",
      "Speed: 4.2ms preprocess, 53.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 73.4ms\n",
      "Speed: 4.1ms preprocess, 73.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.1ms\n",
      "Speed: 6.5ms preprocess, 25.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.7ms\n",
      "Speed: 4.5ms preprocess, 24.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.2ms\n",
      "Speed: 4.4ms preprocess, 33.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.8ms\n",
      "Speed: 4.2ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 52.9ms\n",
      "Speed: 4.1ms preprocess, 52.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 4.1ms preprocess, 26.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.6ms\n",
      "Speed: 9.8ms preprocess, 24.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.7ms\n",
      "Speed: 4.1ms preprocess, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.0ms\n",
      "Speed: 4.2ms preprocess, 45.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 33.6ms\n",
      "Speed: 3.9ms preprocess, 33.6ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "25-10-05 12:27:55 - arcface_weights.h5 will be downloaded to C:\\Users\\Frames/.deepface/weights/arcface_weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/arcface_weights.h5\n",
      "To: C:\\Users\\Frames\\.deepface\\weights\\arcface_weights.h5\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 137M/137M [00:11<00:00, 11.7MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∏ Saved 'No Match' face to unknown_faces/nomatch_20251005_122818.jpg\n",
      "\n",
      "0: 384x640 1 face, 20.4ms\n",
      "Speed: 37.0ms preprocess, 20.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 12.5ms\n",
      "Speed: 2.8ms preprocess, 12.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 24.1ms\n",
      "Speed: 5.0ms preprocess, 24.1ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 16.9ms\n",
      "Speed: 3.3ms preprocess, 16.9ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 22.5ms\n",
      "Speed: 5.6ms preprocess, 22.5ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.5ms\n",
      "Speed: 3.4ms preprocess, 13.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 16.7ms\n",
      "Speed: 3.5ms preprocess, 16.7ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 21.5ms\n",
      "Speed: 5.6ms preprocess, 21.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 23.5ms\n",
      "Speed: 3.4ms preprocess, 23.5ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 17.7ms\n",
      "Speed: 3.5ms preprocess, 17.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 36.1ms\n",
      "Speed: 4.1ms preprocess, 36.1ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 28.7ms\n",
      "Speed: 6.1ms preprocess, 28.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 15.2ms\n",
      "Speed: 3.5ms preprocess, 15.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 15.8ms\n",
      "Speed: 3.5ms preprocess, 15.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 15.0ms\n",
      "Speed: 3.5ms preprocess, 15.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.5ms\n",
      "Speed: 3.5ms preprocess, 14.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.8ms\n",
      "Speed: 3.5ms preprocess, 14.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 16.0ms\n",
      "Speed: 3.5ms preprocess, 16.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 17.4ms\n",
      "Speed: 3.4ms preprocess, 17.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.2ms\n",
      "Speed: 3.4ms preprocess, 13.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.6ms\n",
      "Speed: 3.4ms preprocess, 13.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 17.9ms\n",
      "Speed: 3.4ms preprocess, 17.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.3ms\n",
      "Speed: 3.5ms preprocess, 13.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.5ms\n",
      "Speed: 3.4ms preprocess, 14.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.3ms\n",
      "Speed: 3.5ms preprocess, 13.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.9ms\n",
      "Speed: 3.3ms preprocess, 13.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.2ms\n",
      "Speed: 3.5ms preprocess, 14.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.2ms\n",
      "Speed: 3.2ms preprocess, 13.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "‚ùå Frame not received. Attempting to reconnect...\n",
      "‚úÖ Reconnected successfully!\n",
      "\n",
      "0: 384x640 1 face, 81.0ms\n",
      "Speed: 4.3ms preprocess, 81.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "üì∏ Saved 'No Match' face to unknown_faces/nomatch_20251005_122833.jpg\n",
      "\n",
      "0: 384x640 1 face, 25.5ms\n",
      "Speed: 3.5ms preprocess, 25.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.1ms\n",
      "Speed: 3.5ms preprocess, 14.1ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 21.3ms\n",
      "Speed: 3.3ms preprocess, 21.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 19.4ms\n",
      "Speed: 3.5ms preprocess, 19.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.3ms\n",
      "Speed: 3.4ms preprocess, 13.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.2ms\n",
      "Speed: 3.5ms preprocess, 13.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.6ms\n",
      "Speed: 3.2ms preprocess, 13.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.4ms\n",
      "Speed: 3.2ms preprocess, 13.4ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 15.7ms\n",
      "Speed: 3.4ms preprocess, 15.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 19.5ms\n",
      "Speed: 4.5ms preprocess, 19.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.2ms\n",
      "Speed: 3.5ms preprocess, 14.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.3ms\n",
      "Speed: 3.5ms preprocess, 14.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 15.4ms\n",
      "Speed: 3.5ms preprocess, 15.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 16.2ms\n",
      "Speed: 3.5ms preprocess, 16.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.7ms\n",
      "Speed: 3.4ms preprocess, 14.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.6ms\n",
      "Speed: 3.3ms preprocess, 13.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.7ms\n",
      "Speed: 3.4ms preprocess, 14.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.9ms\n",
      "Speed: 3.5ms preprocess, 14.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.6ms\n",
      "Speed: 3.2ms preprocess, 14.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 15.5ms\n",
      "Speed: 3.5ms preprocess, 15.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 16.1ms\n",
      "Speed: 3.3ms preprocess, 16.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.8ms\n",
      "Speed: 3.4ms preprocess, 14.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.3ms\n",
      "Speed: 3.3ms preprocess, 13.3ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 15.8ms\n",
      "Speed: 3.5ms preprocess, 15.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 22.6ms\n",
      "Speed: 3.4ms preprocess, 22.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.5ms\n",
      "Speed: 3.5ms preprocess, 14.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 15.4ms\n",
      "Speed: 3.5ms preprocess, 15.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.4ms\n",
      "Speed: 3.3ms preprocess, 14.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 13.7ms\n",
      "Speed: 3.4ms preprocess, 13.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 15.2ms\n",
      "Speed: 3.5ms preprocess, 15.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.6ms\n",
      "Speed: 3.3ms preprocess, 14.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 15.5ms\n",
      "Speed: 3.3ms preprocess, 15.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 15.4ms\n",
      "Speed: 3.3ms preprocess, 15.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 23.5ms\n",
      "Speed: 5.9ms preprocess, 23.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 face, 14.4ms\n",
      "Speed: 3.5ms preprocess, 14.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.2ms\n",
      "Speed: 3.5ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.0ms\n",
      "Speed: 3.3ms preprocess, 16.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.7ms\n",
      "Speed: 3.3ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 3.5ms preprocess, 26.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.2ms\n",
      "Speed: 3.5ms preprocess, 15.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.7ms\n",
      "Speed: 3.2ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.2ms\n",
      "Speed: 4.2ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.3ms\n",
      "Speed: 3.4ms preprocess, 13.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 19.6ms\n",
      "Speed: 3.6ms preprocess, 19.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 19.2ms\n",
      "Speed: 3.5ms preprocess, 19.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.8ms\n",
      "Speed: 3.5ms preprocess, 16.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18.8ms\n",
      "Speed: 3.3ms preprocess, 18.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Exiting program.\n"
     ]
    }
   ],
   "source": [
    "# with standardard thresholds\n",
    "# MODIFIED: Added time module for cooldown timer\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "import torch\n",
    "from ultralytics.nn.tasks import DetectionModel\n",
    "\n",
    "# --- Configuration ---\n",
    "# URL for your IP camera's RTSP stream.\n",
    "# Replace with your actual camera URL.\n",
    "# IP_CAMERA_URL = \"rtsp://admin:cctv@121@192.168.1.65:554/Streaming/Channels/101\"\n",
    "IP_CAMERA_URL = 0\n",
    "\n",
    "\n",
    "# Path to your downloaded YOLO model\n",
    "YOLO_MODEL_PATH = \"yolov8n-face-lindevs.pt\"\n",
    "\n",
    "# Path to the folder containing known faces\n",
    "DATASET_PATH = \"dataset/\"\n",
    "\n",
    "# --- NEW: Configuration for saving unknown faces ---\n",
    "# The folder where images of unknown people will be saved.\n",
    "UNKNOWN_FACES_PATH = \"unknown_faces/\"\n",
    "# Cooldown in seconds to prevent saving the same unknown person multiple times.\n",
    "UNKNOWN_CAPTURE_COOLDOWN = 10.0 # seconds\n",
    "\n",
    "# --- Thresholds and Settings ---\n",
    "# A higher confidence reduces false detections of non-face objects. 0.7 is a good balance.\n",
    "YOLO_CONF_THRESHOLD = 0.7\n",
    "# This threshold balances security and convenience.\n",
    "DEEPFACE_DISTANCE_THRESHOLD = 0.6\n",
    "WINDOW_NAME = \"IP Camera Attendance System\"\n",
    "\n",
    "# --- Performance Optimization ---\n",
    "PROCESS_EVERY_N_FRAMES = 5\n",
    "\n",
    "# --- Reconnection Logic ---\n",
    "RECONNECT_DELAY_SECONDS = 5 # How many seconds to wait before trying to reconnect\n",
    "\n",
    "#--- Thresholds and Settings ---\n",
    "# NEW: Add padding in pixels to the face crop to make space for the timestamp\n",
    "PADDING = 40\n",
    "\n",
    "# --- NEW: Create the directory for unknown faces if it doesn't exist ---\n",
    "if not os.path.exists(UNKNOWN_FACES_PATH):\n",
    "    os.makedirs(UNKNOWN_FACES_PATH)\n",
    "    print(f\"Created directory for unknown faces at: {UNKNOWN_FACES_PATH}\")\n",
    "\n",
    "\n",
    "# Check PyTorch GPU availability\n",
    "print(\"PyTorch GPU available:\", torch.cuda.is_available())\n",
    "print(\"PyTorch GPU device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "# Load YOLO model on GPU explicitly\n",
    "torch.serialization.add_safe_globals([DetectionModel])\n",
    "model = YOLO(YOLO_MODEL_PATH)\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "def mark_attendance(name, yolo_confidence, deepface_distance):\n",
    "    \"\"\"\n",
    "    Records a person's attendance in a CSV file, now including YOLO confidence\n",
    "    and DeepFace distance scores.\n",
    "    \"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime(\"%Y-%m-%d\")\n",
    "    time_str = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    csv_file = \"attendance.csv\"\n",
    "    csv_columns = [\"Name\", \"Date\", \"Time\", \"YOLO_Confidence\", \"DeepFace_Distance\"]\n",
    "\n",
    "    if not os.path.exists(csv_file):\n",
    "        df = pd.DataFrame(columns=csv_columns)\n",
    "        df.to_csv(csv_file, index=False)\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    marked_recently = False\n",
    "    if not df.empty:\n",
    "        if 'Date' in df.columns and 'Time' in df.columns:\n",
    "            df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], errors='coerce')\n",
    "            five_minutes_ago = now - datetime.timedelta(minutes=5)\n",
    "            marked_recently = not df[(df['Name'] == name) & (df['Timestamp'] > five_minutes_ago)].empty\n",
    "\n",
    "    if not marked_recently:\n",
    "        yolo_conf_str = f\"{yolo_confidence:.2f}\"\n",
    "        deepface_dist_str = f\"{deepface_distance:.2f}\"\n",
    "\n",
    "        new_entry = pd.DataFrame(\n",
    "            [[name, date, time_str, yolo_conf_str, deepface_dist_str]],\n",
    "            columns=csv_columns\n",
    "        )\n",
    "\n",
    "        df_updated = pd.concat([df.drop(columns=['Timestamp'], errors='ignore'), new_entry], ignore_index=True)\n",
    "        df_updated.to_csv(csv_file, index=False)\n",
    "        print(f\"‚úÖ Attendance Marked: {name} at {time_str} (YOLO: {yolo_conf_str}, DeepFace: {deepface_dist_str})\")\n",
    "\n",
    "# Create a resizable window\n",
    "cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(WINDOW_NAME, 640, 320)\n",
    "\n",
    "# --- Main Loop ---\n",
    "cap = cv2.VideoCapture(IP_CAMERA_URL, cv2.CAP_FFMPEG)\n",
    "frame_counter = 0\n",
    "last_unknown_capture_time = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # --- Automatic Reconnection Logic ---\n",
    "    if not ret:\n",
    "        print(\"‚ùå Frame not received. Attempting to reconnect...\")\n",
    "        cap.release()\n",
    "        time.sleep(RECONNECT_DELAY_SECONDS)\n",
    "        cap = cv2.VideoCapture(IP_CAMERA_URL)\n",
    "        if not cap.isOpened():\n",
    "            print(\"‚ùå Failed to reconnect.\")\n",
    "            time.sleep(RECONNECT_DELAY_SECONDS)\n",
    "        else:\n",
    "            print(\"‚úÖ Reconnected successfully!\")\n",
    "        continue\n",
    "\n",
    "    frame_counter += 1\n",
    "\n",
    "    if frame_counter % PROCESS_EVERY_N_FRAMES == 0:\n",
    "        try:\n",
    "            results = model(frame, conf=YOLO_CONF_THRESHOLD)\n",
    "\n",
    "            for r in results:\n",
    "                for box in r.boxes:\n",
    "                    yolo_confidence = box.conf.item()\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "\n",
    "                    # --- Add padding to the face crop ---\n",
    "                    h_orig, w_orig = frame.shape[:2]\n",
    "                    pad_y1 = max(0, y1 - PADDING)\n",
    "                    pad_x1 = max(0, x1 - PADDING)\n",
    "                    pad_y2 = min(h_orig, y2 + PADDING)\n",
    "                    pad_x2 = min(w_orig, x2 + PADDING)\n",
    "\n",
    "                    face = frame[pad_y1:pad_y2, pad_x1:pad_x2]\n",
    "\n",
    "                    if face.size == 0:\n",
    "                        continue\n",
    "\n",
    "                    result_df_list = DeepFace.find(img_path=face,\n",
    "                                                     db_path=DATASET_PATH,\n",
    "                                                     model_name=\"ArcFace\",\n",
    "                                                     enforce_detection=False,\n",
    "                                                     silent=True)\n",
    "\n",
    "                    if result_df_list and not result_df_list[0].empty:\n",
    "                        best_match = result_df_list[0].iloc[0]\n",
    "                        distance = best_match['distance']\n",
    "\n",
    "                        if distance < DEEPFACE_DISTANCE_THRESHOLD:\n",
    "                            identity_path = best_match['identity']\n",
    "                            name = os.path.basename(os.path.dirname(identity_path))\n",
    "\n",
    "                            mark_attendance(name, yolo_confidence, distance)\n",
    "\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                            cv2.putText(frame, name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                        else:\n",
    "                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                            cv2.putText(frame, \"Unknown\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "                            current_time = time.time()\n",
    "                            if (current_time - last_unknown_capture_time) > UNKNOWN_CAPTURE_COOLDOWN:\n",
    "                                current_datetime = datetime.datetime.now()\n",
    "                                timestamp_str_filename = current_datetime.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                                filename = f\"unknown_{timestamp_str_filename}.jpg\"\n",
    "                                filepath = os.path.join(UNKNOWN_FACES_PATH, filename)\n",
    "                                cv2.imwrite(filepath, face)\n",
    "                                print(f\"üì∏ Saved unknown face to {filepath}\")\n",
    "                                last_unknown_capture_time = current_time\n",
    "                    else:\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                        cv2.putText(frame, \"No Match\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "                        # Optionally save 'No Match' faces here as well if needed\n",
    "                        current_time = time.time()\n",
    "                        if (current_time - last_unknown_capture_time) > UNKNOWN_CAPTURE_COOLDOWN:\n",
    "                            current_datetime = datetime.datetime.now()\n",
    "                            timestamp_str_filename = current_datetime.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                            filename = f\"nomatch_{timestamp_str_filename}.jpg\"\n",
    "                            filepath = os.path.join(UNKNOWN_FACES_PATH, filename)\n",
    "                            cv2.imwrite(filepath, face)\n",
    "                            print(f\"üì∏ Saved 'No Match' face to {filepath}\")\n",
    "                            last_unknown_capture_time = current_time\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during processing: {e}\")\n",
    "\n",
    "    cv2.imshow(WINDOW_NAME, frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Exiting program.\")\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "676c4f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a33b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672ee14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d797ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9d4272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
